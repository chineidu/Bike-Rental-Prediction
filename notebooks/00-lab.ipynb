{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236f62b9",
   "metadata": {},
   "source": [
    "# Lab For Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917effb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228c8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)\n",
    "\n",
    "\n",
    "# Demo (Prevents ruff from removing the unused module import)\n",
    "name: Any\n",
    "category: Literal[\"A\", \"B\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651f550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Projects/Bike-Rental-Prediction\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6889f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83dabdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a5870a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "x = rng.standard_normal(size=(1_000, 10))\n",
    "\n",
    "X_train, X_test = train_test_split(x, test_size=0.2, random_state=123)\n",
    "y_train = rng.standard_normal(size=(X_train.shape[0],))\n",
    "y_test = rng.standard_normal(size=(X_test.shape[0],))\n",
    "\n",
    "params: dict[str, Any] = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor(**params)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "# rf_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fb7b5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Create regression matrices\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",  # for regression\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 6,\n",
    "    \"tree_method\": \"hist\",  # Use 'hist' for CPU, 'gpu_hist' for GPU\n",
    "}\n",
    "n: int = 100\n",
    "\n",
    "# Train the model\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f9e769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of the base model: 1.125\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(dtest_reg)\n",
    "rmse = root_mean_squared_error(y_test, preds)\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "515bcacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.97861+0.00793\ttest-rmse:1.00251+0.03045\n",
      "[1]\ttrain-rmse:0.95530+0.00922\ttest-rmse:0.99990+0.03146\n",
      "[2]\ttrain-rmse:0.93566+0.01087\ttest-rmse:0.99963+0.03280\n",
      "[3]\ttrain-rmse:0.91714+0.01274\ttest-rmse:1.00122+0.03374\n",
      "[4]\ttrain-rmse:0.90072+0.01365\ttest-rmse:1.00416+0.03115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.978613</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007929</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.002512</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.030454</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.955297</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.009222</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.999901</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.031463</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.935665</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.010871</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.999630</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.032802</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "\u001b[1;36m0\u001b[0m         \u001b[1;36m0.978613\u001b[0m        \u001b[1;36m0.007929\u001b[0m        \u001b[1;36m1.002512\u001b[0m       \u001b[1;36m0.030454\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m         \u001b[1;36m0.955297\u001b[0m        \u001b[1;36m0.009222\u001b[0m        \u001b[1;36m0.999901\u001b[0m       \u001b[1;36m0.031463\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m         \u001b[1;36m0.935665\u001b[0m        \u001b[1;36m0.010871\u001b[0m        \u001b[1;36m0.999630\u001b[0m       \u001b[1;36m0.032802\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "cv_results = xgb.cv(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=20,\n",
    "    nfold=5,\n",
    "    metrics={\"rmse\"},\n",
    "    seed=123,\n",
    "    as_pandas=True,\n",
    "    callbacks=[\n",
    "        xgb.callback.EvaluationMonitor(show_stdv=True),\n",
    "        xgb.callback.EarlyStopping(rounds=3),\n",
    "    ],\n",
    ")\n",
    "console.print(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea33cc8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ffff; text-decoration-color: #00ffff\">Optimal boosting rounds: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;255;255mOptimal boosting rounds: \u001b[0m\u001b[1;36m3\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.978613</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.007929</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.002512</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.030454</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.955297</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.009222</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.999901</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.031463</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.935665</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.010871</span>        <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.999630</span>       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.032802</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "   train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std\n",
       "\u001b[1;36m0\u001b[0m         \u001b[1;36m0.978613\u001b[0m        \u001b[1;36m0.007929\u001b[0m        \u001b[1;36m1.002512\u001b[0m       \u001b[1;36m0.030454\u001b[0m\n",
       "\u001b[1;36m1\u001b[0m         \u001b[1;36m0.955297\u001b[0m        \u001b[1;36m0.009222\u001b[0m        \u001b[1;36m0.999901\u001b[0m       \u001b[1;36m0.031463\u001b[0m\n",
       "\u001b[1;36m2\u001b[0m         \u001b[1;36m0.935665\u001b[0m        \u001b[1;36m0.010871\u001b[0m        \u001b[1;36m0.999630\u001b[0m       \u001b[1;36m0.032802\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Test RMSE: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0805</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;255;0mTest RMSE: \u001b[0m\u001b[1;36m1.0805\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the optimal number of boosting rounds\n",
    "best_num_rounds: int = len(cv_results)\n",
    "console.print(f\"Optimal boosting rounds: {best_num_rounds}\", style=\"success\")\n",
    "console.print(cv_results.tail())\n",
    "\n",
    "# Step 2: Train final model with optimal rounds\n",
    "final_model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=best_num_rounds,\n",
    ")\n",
    "\n",
    "# Step 3: Evaluate on test set\n",
    "test_preds = final_model.predict(dtest_reg)\n",
    "test_rmse = root_mean_squared_error(y_test, test_preds)\n",
    "console.print(f\"Test RMSE: {test_rmse:.4f}\", style=\"info\")\n",
    "\n",
    "\n",
    "# Step 4: Save the model\n",
    "final_model.save_model(\"xgboost_model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff31f7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgboost.core'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(final_model).__module__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f8a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a549b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.config import app_config\n",
    "from src.ml.feature_engineering import FeatureEngineer\n",
    "from src.ml.trainer import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9cca5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">Shape: </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13903</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\">, </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;0;255;0mShape: \u001b[0m\u001b[1;38;2;0;255;0m(\u001b[0m\u001b[1;36m13903\u001b[0m\u001b[38;2;0;255;0m, \u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;38;2;0;255;0m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>datetime</th><th>season</th><th>yr</th><th>mnth</th><th>hr</th><th>holiday</th><th>weekday</th><th>workingday</th><th>weathersit</th><th>temp</th><th>atemp</th><th>hum</th><th>windspeed</th><th>casual</th><th>registered</th><th>cnt</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;2011-01-01 00:00:00&quot;</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>6</td><td>0</td><td>1</td><td>0.24</td><td>0.2879</td><td>0.81</td><td>0.0</td><td>3</td><td>13</td><td>16</td></tr><tr><td>&quot;2011-01-01 01:00:00&quot;</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>6</td><td>0</td><td>1</td><td>0.22</td><td>0.2727</td><td>0.8</td><td>0.0</td><td>8</td><td>32</td><td>40</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 16)\n",
       "┌─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬─────┬────────┬─────┐\n",
       "│ dat ┆ sea ┆ yr  ┆ mnt ┆ hr  ┆ hol ┆ wee ┆ wor ┆ wea ┆ tem ┆ ate ┆ hum ┆ win ┆ cas ┆ regist ┆ cnt │\n",
       "│ eti ┆ son ┆ --- ┆ h   ┆ --- ┆ ida ┆ kda ┆ kin ┆ the ┆ p   ┆ mp  ┆ --- ┆ dsp ┆ ual ┆ ered   ┆ --- │\n",
       "│ me  ┆ --- ┆ i64 ┆ --- ┆ i64 ┆ y   ┆ y   ┆ gda ┆ rsi ┆ --- ┆ --- ┆ f64 ┆ eed ┆ --- ┆ ---    ┆ i64 │\n",
       "│ --- ┆ i64 ┆     ┆ i64 ┆     ┆ --- ┆ --- ┆ y   ┆ t   ┆ f64 ┆ f64 ┆     ┆ --- ┆ i64 ┆ i64    ┆     │\n",
       "│ str ┆     ┆     ┆     ┆     ┆ i64 ┆ i64 ┆ --- ┆ --- ┆     ┆     ┆     ┆ f64 ┆     ┆        ┆     │\n",
       "│     ┆     ┆     ┆     ┆     ┆     ┆     ┆ i64 ┆ i64 ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "╞═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪═════╪════════╪═════╡\n",
       "│ 201 ┆ 1   ┆ 0   ┆ 1   ┆ 0   ┆ 0   ┆ 6   ┆ 0   ┆ 1   ┆ 0.2 ┆ 0.2 ┆ 0.8 ┆ 0.0 ┆ 3   ┆ 13     ┆ 16  │\n",
       "│ 1-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 4   ┆ 879 ┆ 1   ┆     ┆     ┆        ┆     │\n",
       "│ 1-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 00  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 201 ┆ 1   ┆ 0   ┆ 1   ┆ 1   ┆ 0   ┆ 6   ┆ 0   ┆ 1   ┆ 0.2 ┆ 0.2 ┆ 0.8 ┆ 0.0 ┆ 8   ┆ 32     ┆ 40  │\n",
       "│ 1-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆ 2   ┆ 727 ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 1-0 ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 1   ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 01: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 00: ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "│ 00  ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆     ┆        ┆     │\n",
       "└─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴─────┴────────┴─────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 21:34:09 - mlflow_tracker - [INFO] - Initialized MLFlowTracker with experiment: bike_rental_experiment\n",
      "2025-10-03 21:34:09 - trainer - [INFO] - Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "fp: str = \"../../../../Documents/data_dump/bike_data/database.parquet\"\n",
    "data: pl.DataFrame = pl.read_parquet(fp)\n",
    "console.print(f\"Shape: {data.shape}\", style=\"info\")\n",
    "display(data.head(2))\n",
    "\n",
    "trainer = ModelTrainer(data, config=app_config.feature_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d60d8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9086ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureConfig(lag_features=[Lags(feature='cnt', lags=[0, 1, 24]), Lags(feature='hr', lags=[1, 24]), Lags(feature='temp', lags=[1, 3]), Lags(feature='hum', lags=[1, 3])], diff_features=[Diffs(feature='cnt', diffs=[1, 2]), Diffs(feature='hr', diffs=[1, 24]), Diffs(feature='temp', diffs=[1, 2, 24]), Diffs(feature='hum', diffs=[1, 2])], interaction_features=[InteractionFeats(feature_1='temp', feature_2='hum', operation='add'), InteractionFeats(feature_1='hum', feature_2='hr', operation='add')], rolling_features=[Windows(feature='temp', windows=[3, 6]), Windows(feature='hum', windows=[3, 6])], drop_features=['atemp', 'windspeed', 'casual', 'registered', 'datetime', 'cnt', 'yr'], target_col='cnt')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_config.feature_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f04938ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 21:34:14 - mlflow_tracker - [INFO] - Started MLflow run: 84cb99a26f5b4318a5e2229cc69d306b (name: run_2025-10-03T21:34:13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-03 21:34:14,078] A new study created in memory with name: no-name-7169ee88-fe0f-4db7-a81c-4420f9fdda90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 21:34:14 - mlflow_tracker - [INFO] - Started MLflow run: b967688ff1c4482fa6ea9cf63cbdbcec (name: run_2025-10-03T21:34:14)\n",
      "Trial 0: Mean RMSE = 60.67\n",
      "🏃 View run run_2025-10-03T21:34:14 at: http://0.0.0.0:6060/#/experiments/941431890320196348/runs/b967688ff1c4482fa6ea9cf63cbdbcec\n",
      "🧪 View experiment at: http://0.0.0.0:6060/#/experiments/941431890320196348\n",
      "2025-10-03 21:35:26 - mlflow_tracker - [INFO] - Ended MLflow run with status: FINISHED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-03 21:35:26,957] Trial 0 finished with value: 60.67 and parameters: {'n_estimators': 144, 'max_depth': 20, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_features': None, 'bootstrap': True}. Best is trial 0 with value: 60.67.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-03 21:35:26 - trainer - [INFO] - Initial trial 0 achieved value: 60.67\n",
      "Best trial:\n",
      "2025-10-03 21:35:27 - mlflow_tracker - [INFO] - ✅ Successfully logged RandomForestRegressor model and metadata\n",
      "🏃 View run run_2025-10-03T21:34:13 at: http://0.0.0.0:6060/#/experiments/941431890320196348/runs/84cb99a26f5b4318a5e2229cc69d306b\n",
      "🧪 View experiment at: http://0.0.0.0:6060/#/experiments/941431890320196348\n",
      "2025-10-03 21:35:27 - mlflow_tracker - [INFO] - Ended MLflow run with status: FINISHED\n"
     ]
    }
   ],
   "source": [
    "# data_dict: dict[str, Any] = trainer.prepare_data()\n",
    "\n",
    "trainer._hyperparameter_tuning_random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fd20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9401ddb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b97810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.exp_tracking.mlflow import MLFlowTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728b642d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccca7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# port: int = 6060\n",
    "# url: str = f\"http://0.0.0.0:{port}\"\n",
    "\n",
    "# mlflow.set_tracking_uri(url)\n",
    "# experiment_name: str = \"Demo Experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Callable\n",
    "\n",
    "type WriteFn = Callable[[Any, Path], None]\n",
    "\n",
    "\n",
    "class ArtifactsType(str, Enum):\n",
    "    JSON = \"json\"\n",
    "    TXT = \"txt\"\n",
    "    YAML = \"yaml\"\n",
    "    ANY = \"joblib\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "port: int = 6060\n",
    "url: str = f\"http://0.0.0.0:{port}\"\n",
    "experiment_name: str = \"Demo Experiment\"\n",
    "\n",
    "mlflow_tracker = MLFlowTracker(experiment_name=experiment_name, tracking_uri=url)\n",
    "mlflow_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc833d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow_tracker.start_run() as run:\n",
    "    _ = mlflow_tracker.start_run(tags={\"mlflow.runName\": \"Initial model training\"})\n",
    "    # Log the model\n",
    "    mlflow_tracker.log_model(\n",
    "        model_name=\"RandomForestRegressor\",\n",
    "        model=rf_reg,\n",
    "        input_example=pl.from_numpy(X_test),\n",
    "    )\n",
    "    # mlflow.sklearn.log_model(sk_model=rf_reg, input_example=X_test, name=\"rf_reg\")\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow_tracker.log_metrics(\n",
    "        {\"mse\": 45.0, \"rmse\": 5.0, \"mae\": 4.0, \"r2\": 0.8, \"msle\": 0.1, \"medae\": 3.0}\n",
    "    )\n",
    "\n",
    "    # Log the hyperparameter\n",
    "    mlflow_tracker.log_params(params=params)\n",
    "\n",
    "    # Log plots\n",
    "    # mlflow.log_figure(fig1, \"time_series_demand.png\")\n",
    "    # mlflow.log_figure(fig2, \"box_weekend.png\")\n",
    "\n",
    "    # Log artifacts saved in the local file system\n",
    "    # mlflow_tracker.log_mlflow_artifact()\n",
    "    # log_mlflow_artifact(\"./plots/correlation_wf_target.png\", artifact_dest=\"plots\")\n",
    "\n",
    "    mlflow_tracker.log_mlflow_artifact(\n",
    "        object={\"name\": \"wuraola\", \"role\": \"medical doctor\", \"age\": 29},\n",
    "        object_type=ArtifactsType.YAML,\n",
    "        filename=\"my_metadata\",\n",
    "        artifact_dest=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "from src.config.config import app_config\n",
    "\n",
    "fp: str = \"../src/config/config.yaml\"\n",
    "\n",
    "\n",
    "config: DictConfig = OmegaConf.load(fp).config\n",
    "\n",
    "cfg = OmegaConf.to_container(config, resolve=True)\n",
    "console.print(cfg)\n",
    "app_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164388f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp: str = \"../../../../Documents/data_dump/bike_data/database.parquet\"\n",
    "data: pl.DataFrame = pl.read_parquet(fp)\n",
    "console.print(f\"Shape: {data.shape}\", style=\"info\")\n",
    "\n",
    "feat_eng = FeatureEngineer(data=data, config=app_config.feature_config)\n",
    "console.print(feat_eng)\n",
    "\n",
    "feat_eng.create_all_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f22865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8c4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aca3783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39f5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "import yaml\n",
    "\n",
    "\n",
    "def log_mlflow_artifact_v1(local_path: str, artifact_dest: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Log a local file to MLflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_path : str\n",
    "        Path to the local file to log.\n",
    "    artifact_dest : str | None\n",
    "        (Optional) Run-relative directory in the MLflow artifact store.\n",
    "    \"\"\"\n",
    "    if not isinstance(local_path, Path):\n",
    "        file_path = Path(local_path)\n",
    "    if not file_path.is_file():\n",
    "        raise FileNotFoundError(f\"Cannot find artifact at {local_path}\")\n",
    "    # Log it under artifact_dest (or root if None)\n",
    "    mlflow.log_artifact(str(file_path), artifact_path=artifact_dest)\n",
    "\n",
    "\n",
    "def _get_run_name(run_name: str | None = None) -> str:\n",
    "    if run_name is None:\n",
    "        run_name = f\"run_{datetime.now().isoformat(timespec='seconds')}\"\n",
    "    return run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8dffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    my_path = Path(tmpdir, \"my_file.json\")\n",
    "    print(my_path)\n",
    "    with open(my_path, \"w\") as f:\n",
    "        json.dump({\"name\": \"wuraola\", \"role\": \"medical doctor\"}, fp=f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "type WriteFn = Callable[[Any, Path], None]\n",
    "\n",
    "\n",
    "class ArtifactsType(str, Enum):\n",
    "    JSON = \"json\"\n",
    "    TXT = \"txt\"\n",
    "    YAML = \"yaml\"\n",
    "    ANY = \"joblib\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "def write_json(object: dict[str, Any] | Any, filepath: Path, indent: int = 2) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(object, fp=f, indent=indent)\n",
    "\n",
    "\n",
    "def write_txt(object: list[Any], filepath: Path) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for line in object:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "def write_yaml(object: dict[str, Any] | Any, filepath: Path) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(object, f)\n",
    "\n",
    "\n",
    "def write_pickle(object: dict[str, Any] | Any, filepath: Path) -> None:\n",
    "    joblib.dump(object, filepath)\n",
    "\n",
    "\n",
    "def log_mlflow_artifact(\n",
    "    object: Any,\n",
    "    object_type: ArtifactsType,\n",
    "    filename: str,\n",
    "    artifact_dest: str | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log a local file to MLflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_path : str\n",
    "        Path to the local file to log.\n",
    "    artifact_dest : str | None\n",
    "        (Optional) Run-relative directory in the MLflow artifact store.\n",
    "    \"\"\"\n",
    "    if object_type == ArtifactsType.JSON:\n",
    "        write_fn = write_json\n",
    "    elif object_type == ArtifactsType.TXT:\n",
    "        write_fn = write_txt\n",
    "    elif object_type == ArtifactsType.YAML:\n",
    "        write_fn = write_yaml\n",
    "    elif object_type == ArtifactsType.ANY:\n",
    "        write_fn = write_pickle\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object type: {object_type}\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        tmp_path = Path(tmpdir) / f\"{filename}-artifact.{object_type}\"\n",
    "        write_fn(object, tmp_path)\n",
    "        mlflow.log_artifact(tmp_path, artifact_path=artifact_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.end_run()\n",
    "\n",
    "# mlflow.set_experiment(experiment_name)\n",
    "# with mlflow.start_run(run_name=_get_run_name()) as run:\n",
    "#     # Log the model\n",
    "#     mlflow.sklearn.log_model(sk_model=rf_reg, input_example=X_test, name=\"rf_reg\")\n",
    "\n",
    "#     # Log the metrics\n",
    "#     mlflow.log_metrics(\n",
    "#         {\"mse\": 45.0, \"rmse\": 5.0, \"mae\": 4.0, \"r2\": 0.8, \"msle\": 0.1, \"medae\": 3.0}\n",
    "#     )\n",
    "\n",
    "#     # Log the hyperparameter\n",
    "#     mlflow.log_params(params=params)\n",
    "\n",
    "#     # Log plots\n",
    "#     # mlflow.log_figure(fig1, \"time_series_demand.png\")\n",
    "#     # mlflow.log_figure(fig2, \"box_weekend.png\")\n",
    "\n",
    "#     # Log artifacts saved in the local file system\n",
    "#     log_mlflow_artifact(\"./plots/correlation_wf_target.png\", artifact_dest=\"plots\")\n",
    "#     # log_mlflow_artifact(\"./my_metadata.json\", artifact_dest=\"metadata\")\n",
    "#     log_mlflow_artifact(\n",
    "#         object={\"name\": \"wuraola\", \"role\": \"medical doctor\"},\n",
    "#         object_type=ArtifactsType.YAML,\n",
    "#         filename=\"my_metadata\",\n",
    "#         artifact_dest=None,\n",
    "#     )\n",
    "# #"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26bc72c5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\"\"\"This module provides utilities for model training.\n",
    "Inspired by: https://github.com/airscholar/astro-salesforecast/blob/main/include/ml_models/train_models.py\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import tempfile\n",
    "from typing import Any, Literal\n",
    "\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from include import PACKAGE_PATH, create_logger\n",
    "from include.ml.diagnostics import diagnose_model_performance\n",
    "from include.ml.ensemble_model import EnsembleModel\n",
    "from include.ml.visualization import ModelVisualizerMatMatplotlib, ModelVisualizerPlotly\n",
    "from include.utilities.feature_engineering import FeatureEngineer\n",
    "from include.utilities.mlflow_s3_utils import MLflowS3Manager\n",
    "from include.utilities.mlflow_utils import MLflowManager\n",
    "from include.utilities.s3_verification import (\n",
    "    log_s3_verification_results,\n",
    "    verify_s3_artifacts,\n",
    ")\n",
    "\n",
    "logger = create_logger(__name__)\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a ModelTrainer object.\n",
    "\n",
    "        The ModelTrainer object is used to train and diagnose the performance of\n",
    "        machine learning models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_config : ModelsConfig\n",
    "            MLflow models configuration\n",
    "        training_config : TrainingConfig\n",
    "            Training configuration\n",
    "        mlflow_manager : MLflowManager\n",
    "            Manager for MLflow\n",
    "        feature_engineer : FeatureEngineer\n",
    "            Feature engineering utilities\n",
    "        models : dict[str, Any]\n",
    "            Trained models\n",
    "        scalers : dict[str, StandardScaler]\n",
    "            Scalers used for feature scaling\n",
    "        label_encoders : dict[str, LabelEncoder]\n",
    "            Label encoders used for categorical encoding\n",
    "        \"\"\"\n",
    "        self.model_config = app_config.models\n",
    "        self.training_config = app_config.training\n",
    "        self.mlflow_manager = MLflowManager()\n",
    "        self.feature_engineer = FeatureEngineer()\n",
    "        self.models: dict[str, Any] = {}\n",
    "        self.scalers: dict[str, StandardScaler] = {}\n",
    "        self.label_encoders: dict[str, LabelEncoder] = {}\n",
    "\n",
    "    @property\n",
    "    def run_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Property to get the run name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Run name.\n",
    "        \"\"\"\n",
    "        return self.mlflow_manager.get_run_id(None)\n",
    "\n",
    "    def prepare_data(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        target_col: str = \"sales\",\n",
    "        group_cols: list[str] | None = None,\n",
    "        categorical_cols: list[str] | None = None,\n",
    "    ) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare data for training and validation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pl.DataFrame\n",
    "            Input DataFrame.\n",
    "        target_col : str, optional\n",
    "            Target column name. Defaults to \"sales\".\n",
    "        group_cols : list[str] | None, optional\n",
    "            Columns to group by when creating lag and rolling features. Defaults to None.\n",
    "        categorical_cols : list[str] | None, optional\n",
    "            Columns to create interaction features for. Defaults to None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]\n",
    "            Tuple of (train_df, val_df, test_df) DataFrames.\n",
    "        \"\"\"\n",
    "        required_cols: list[str] = [\"date\", target_col]\n",
    "        if group_cols:\n",
    "            required_cols.extend(group_cols)\n",
    "\n",
    "        missing_cols: list[str] = list(set(required_cols) - set(df.columns))\n",
    "        if missing_cols:\n",
    "            raise ValueError(\n",
    "                f\"❌ Missing required columns for training: {missing_cols}\"\n",
    "            )\n",
    "\n",
    "        # Feature engineering\n",
    "        df_features: pl.DataFrame = self.feature_engineer.create_all_features(\n",
    "            df,\n",
    "            target_col=target_col,\n",
    "            date_col=\"date\",\n",
    "            group_cols=group_cols,\n",
    "            categorical_cols=categorical_cols,\n",
    "        )\n",
    "        # Sort the data chronologically (for time series)\n",
    "        df_features = df_features.sort(by=[\"date\"], descending=False)\n",
    "\n",
    "        # Split data: Use the most recent data for validation (mimick real-world scenario)\n",
    "        train_size: int = int(\n",
    "            len(df_features)\n",
    "            * (\n",
    "                1\n",
    "                - self.training_config.test_size\n",
    "                - self.training_config.validation_size\n",
    "            )\n",
    "        )\n",
    "        validation_size: int = int(\n",
    "            len(df_features) * self.training_config.validation_size\n",
    "        )\n",
    "\n",
    "        # Drop rows with NaN in target column\n",
    "        train_df: pl.DataFrame = df_features[:train_size].drop_nulls(\n",
    "            subset=[target_col]\n",
    "        )\n",
    "        val_df: pl.DataFrame = df_features[\n",
    "            train_size : train_size + validation_size\n",
    "        ].drop_nulls(subset=[target_col])\n",
    "        test_df: pl.DataFrame = df_features[train_size + validation_size :].drop_nulls(\n",
    "            subset=[target_col]\n",
    "        )\n",
    "        extras: dict[str, Any] = {\n",
    "            \"train_size\": train_size,\n",
    "            \"validation_size\": validation_size,\n",
    "            \"test_size\": len(test_df),\n",
    "        }\n",
    "        logger.info(f\"Data split - {json.dumps(extras)}\")\n",
    "\n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def preprocess_features(\n",
    "        self,\n",
    "        train_df: pl.DataFrame,\n",
    "        val_df: pl.DataFrame,\n",
    "        test_df: pl.DataFrame,\n",
    "        target_col: str,\n",
    "        excluded_cols: list[str] = [\"date\"],  # noqa: B006\n",
    "    ) -> tuple[\n",
    "        pl.DataFrame, pl.DataFrame, pl.DataFrame, pl.Series, pl.Series, pl.Series\n",
    "    ]:\n",
    "        # Separate features and target\n",
    "        \"\"\"\n",
    "        Preprocess features for training and evaluation.\n",
    "\n",
    "        This function separates features and target from the input DataFrame, encodes\n",
    "        categorical features using LabelEncoder, and scales the features using StandardScaler.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pl.DataFrame\n",
    "            Training data.\n",
    "        val_df : pl.DataFrame\n",
    "            Validation data.\n",
    "        test_df : pl.DataFrame\n",
    "            Testing data.\n",
    "        target_col : str\n",
    "            Target column name.\n",
    "        excluded_cols : list[str]\n",
    "            Columns to exclude from the feature set. Defaults to [\"date\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_train_scaled : pl.DataFrame\n",
    "            Scaled training features.\n",
    "        X_val_scaled : pl.DataFrame\n",
    "            Scaled validation features.\n",
    "        X_test_scaled : pl.DataFrame\n",
    "            Scaled testing features.\n",
    "        y_train : pl.Series\n",
    "            Training target.\n",
    "        y_val : pl.Series\n",
    "            Validation target.\n",
    "        y_test : pl.Series\n",
    "            Testing target.\n",
    "        \"\"\"\n",
    "        X_train: pl.DataFrame = train_df.drop([target_col] + excluded_cols)\n",
    "        X_val: pl.DataFrame = val_df.drop([target_col] + excluded_cols)\n",
    "        X_test: pl.DataFrame = test_df.drop([target_col] + excluded_cols)\n",
    "\n",
    "        y_train: pl.Series = train_df[target_col]\n",
    "        y_val: pl.Series = val_df[target_col]\n",
    "        y_test: pl.Series = test_df[target_col]\n",
    "\n",
    "        # Encode categorical features\n",
    "        # Note: sklearn's LabelEncoder raises on unseen labels. We map unseen labels to -1\n",
    "        # so validation/test data won't break the pipeline. We keep encoders in\n",
    "        # self.label_encoders to reuse during inference.\n",
    "        cat_cols: list[str] = X_train.select(cs.string()).columns\n",
    "        for var in cat_cols:\n",
    "            train_values = X_train[var].to_list()\n",
    "\n",
    "            if var not in self.label_encoders:\n",
    "                le = LabelEncoder()\n",
    "                encoded_train = le.fit_transform(train_values)\n",
    "                self.label_encoders[var] = le\n",
    "            else:\n",
    "                le = self.label_encoders[var]\n",
    "                try:\n",
    "                    encoded_train = le.transform(train_values)\n",
    "                except ValueError:\n",
    "                    mapping = {c: i for i, c in enumerate(le.classes_)}\n",
    "                    encoded_train = [mapping.get(v, -1) for v in train_values]\n",
    "\n",
    "            # Build mapping for known classes to safely encode val/test (unknown -> -1)\n",
    "            mapping = {c: i for i, c in enumerate(self.label_encoders[var].classes_)}\n",
    "\n",
    "            def _encode_list(\n",
    "                values: list[str], mapping: dict[str, int] = mapping\n",
    "            ) -> list[int]:\n",
    "                \"\"\"Encode a list of categorical values using an existing mapping.\"\"\"\n",
    "                return [mapping.get(v, -1) for v in values]\n",
    "\n",
    "            val_values: list[Any] = X_val[var].to_list()\n",
    "            test_values: list[Any] = X_test[var].to_list()\n",
    "\n",
    "            encoded_val: list[int] = _encode_list(val_values)\n",
    "            encoded_test: list[int] = _encode_list(test_values)\n",
    "\n",
    "            # Attach encoded columns back as small-int (Int8). -1 reserved for unknowns.\n",
    "            X_train = X_train.with_columns(\n",
    "                pl.Series(var, values=encoded_train, dtype=pl.Int8)\n",
    "            )\n",
    "            X_val = X_val.with_columns(\n",
    "                pl.Series(var, values=encoded_val, dtype=pl.Int8)\n",
    "            )\n",
    "            X_test = X_test.with_columns(\n",
    "                pl.Series(var, values=encoded_test, dtype=pl.Int8)\n",
    "            )\n",
    "\n",
    "        # Track feature columns used for modeling (post-encoding, pre-scaling)\n",
    "        self.feature_cols: list[str] = X_train.columns  # type: ignore[attr-defined]\n",
    "\n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.fit_transform(X_train), schema=X_train.columns\n",
    "        )\n",
    "        X_val_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.transform(X_val), schema=X_val.columns\n",
    "        )\n",
    "        X_test_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.transform(X_test), schema=X_test.columns\n",
    "        )\n",
    "\n",
    "        self.scalers[\"standard\"] = scaler\n",
    "\n",
    "        return (X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test)\n",
    "\n",
    "    def calculate_metrics(\n",
    "        self, y_true: np.ndarray, y_pred: np.ndarray\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate and return a dictionary with the following metrics:\n",
    "        - root mean squared error (rmse)\n",
    "        - mean absolute error (mae)\n",
    "        - mean absolute percentage error (mape)\n",
    "        - R-squared (r2)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : np.ndarray\n",
    "            True labels.\n",
    "        y_pred : np.ndarray\n",
    "            Predicted labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        metrics : dict[str, float]\n",
    "            Dictionary with the calculated metrics.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "            \"mape\": np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "            \"r2\": r2_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def train_xgboost(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "    ) -> xgb.XGBRegressor:  # type: ignore\n",
    "        \"\"\"\n",
    "        Train an XGBoost model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Training features.\n",
    "        y_train : np.ndarray\n",
    "            Training target.\n",
    "        X_val : np.ndarray\n",
    "            Validation features.\n",
    "        y_val : np.ndarray\n",
    "            Validation target.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : xgboost.XGBRegressor\n",
    "            Trained model.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info(\"Training XGBoost model\")\n",
    "\n",
    "        best_params = self.model_config.xgboost.params\n",
    "        best_params[\"early_stopping_rounds\"] = 50\n",
    "        model = xgb.XGBRegressor(**best_params)  # type: ignore\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "        self.models[\"xgboost\"] = model\n",
    "        return model\n",
    "\n",
    "    def train_lightgbm(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "    ) -> lgb.LGBMRegressor:  # type: ignore\n",
    "        \"\"\"\n",
    "        Train a LightGBM model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Training features.\n",
    "        y_train : np.ndarray\n",
    "            Training target.\n",
    "        X_val : np.ndarray\n",
    "            Validation features.\n",
    "        y_val : np.ndarray\n",
    "            Validation target.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : lgb.LGBMRegressor\n",
    "            Trained model.\n",
    "        \"\"\"\n",
    "        logger.info(\"Training LightGBM model\")\n",
    "\n",
    "        # Access model config using attribute access (ModelsConfig Pydantic model)\n",
    "        best_params = self.model_config.lightgbm.params\n",
    "\n",
    "        model = lgb.LGBMRegressor(**best_params)  # type: ignore\n",
    "\n",
    "        # Use sklearn-compatible early stopping parameter to avoid callback API differences\n",
    "        # This is compatible with scikit-learn API wrapper for LightGBM\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(50)],\n",
    "        )\n",
    "\n",
    "        self.models[\"lightgbm\"] = model\n",
    "        return model\n",
    "\n",
    "    def train_all_models(\n",
    "        self,\n",
    "        train_df: pl.DataFrame,\n",
    "        val_df: pl.DataFrame,\n",
    "        test_df: pl.DataFrame,\n",
    "        target_col: str = \"sales\",\n",
    "    ) -> dict[str, dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Train multiple models (XGBoost, LightGBM, and Prophet (optional)) on the given data, and\n",
    "        log the results to MLflow. The models are trained on the training data, and evaluated on\n",
    "        the validation data. The best model is selected based on the validation R2 score, and the\n",
    "        ensemble model is created using the best model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pl.DataFrame\n",
    "            Training data.\n",
    "        val_df : pl.DataFrame\n",
    "            Validation data.\n",
    "        test_df : pl.DataFrame\n",
    "            Testing data.\n",
    "        target_col : str, optional\n",
    "            Target column name, by default \"sales\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : dict[str, dict[str, Any]]\n",
    "            A dictionary containing the results of the model training, including the trained models,\n",
    "            the metrics, and the predictions.\n",
    "        \"\"\"\n",
    "        results: dict[str, dict[str, Any]] = {}\n",
    "\n",
    "        # Start MLflow run\n",
    "        _ = self.mlflow_manager.start_run(\n",
    "            run_name=f\"{app_config.mlflow.experiment_name}_training_{datetime.now().isoformat(timespec='seconds')}\",\n",
    "            tags={\"model_type\": \"ensemble\"},\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Preprocess data\n",
    "            (\n",
    "                X_train_df,\n",
    "                X_val_df,\n",
    "                X_test_df,\n",
    "                y_train_series,\n",
    "                y_val_series,\n",
    "                y_test_series,\n",
    "            ) = self.preprocess_features(train_df, val_df, test_df, target_col)\n",
    "            # Convert to Arrays\n",
    "            X_train: np.ndarray = X_train_df.to_numpy()\n",
    "            X_val: np.ndarray = X_val_df.to_numpy()\n",
    "            X_test: np.ndarray = X_test_df.to_numpy()\n",
    "            y_train: np.ndarray = y_train_series.to_numpy()\n",
    "            y_val: np.ndarray = y_val_series.to_numpy()\n",
    "            y_test: np.ndarray = y_test_series.to_numpy()\n",
    "\n",
    "            # Log data stats\n",
    "            self.mlflow_manager.log_params(\n",
    "                {\n",
    "                    \"train_size\": len(train_df),\n",
    "                    \"val_size\": len(val_df),\n",
    "                    \"test_size\": len(test_df),\n",
    "                    \"n_features\": X_train.shape[1],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # ================================\n",
    "            # ======= XGBoost Training =======\n",
    "            # ================================\n",
    "            xgb_model = self.train_xgboost(X_train, y_train, X_val, y_val)\n",
    "            xgb_pred = xgb_model.predict(X_test)\n",
    "            xgb_metrics = self.calculate_metrics(y_test, xgb_pred)\n",
    "\n",
    "            self.mlflow_manager.log_metrics(\n",
    "                {f\"xgboost_{k}\": v for k, v in xgb_metrics.items()}\n",
    "            )\n",
    "            self.mlflow_manager.log_model(\n",
    "                xgb_model, \"xgboost\", input_example=X_train_df.head()\n",
    "            )\n",
    "\n",
    "            # Log feature importance\n",
    "            feature_importance: pl.DataFrame = (\n",
    "                pl.DataFrame(\n",
    "                    {\n",
    "                        \"feature\": self.feature_cols,\n",
    "                        \"importance\": xgb_model.feature_importances_,\n",
    "                    }\n",
    "                )\n",
    "                .sort(\"importance\", descending=True)\n",
    "                .head(20)\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Top XGBoost features:\\n{feature_importance.to_dicts()}\")\n",
    "            self.mlflow_manager.log_params(\n",
    "                {\n",
    "                    f\"xgb_top_feature_{idx}\": f\"{row[0]} ({row[1]:.4f})\"\n",
    "                    for idx, row in enumerate(feature_importance.iter_rows(), start=1)\n",
    "                }\n",
    "            )\n",
    "\n",
    "            results[\"xgboost\"] = {\n",
    "                \"model\": xgb_model,\n",
    "                \"metrics\": xgb_metrics,\n",
    "                \"predictions\": xgb_pred,\n",
    "            }\n",
    "\n",
    "            # ================================\n",
    "            # ======= LightGBM Training ======\n",
    "            # ================================\n",
    "            try:\n",
    "                lgb_model = self.train_lightgbm(X_train, y_train, X_val, y_val)\n",
    "                lgb_pred = lgb_model.predict(X_test)\n",
    "                lgb_metrics = self.calculate_metrics(y_test, lgb_pred)\n",
    "\n",
    "                self.mlflow_manager.log_metrics(\n",
    "                    {f\"lightgbm_{k}\": v for k, v in lgb_metrics.items()}\n",
    "                )\n",
    "                self.mlflow_manager.log_model(\n",
    "                    lgb_model, \"lightgbm\", input_example=X_train_df.head()\n",
    "                )\n",
    "\n",
    "                # Log feature importance for LightGBM\n",
    "                lgb_importance: pl.DataFrame = (\n",
    "                    pl.DataFrame(\n",
    "                        {\n",
    "                            \"feature\": self.feature_cols,\n",
    "                            \"importance\": lgb_model.feature_importances_,\n",
    "                        }\n",
    "                    )\n",
    "                    .sort(\"importance\", descending=True)\n",
    "                    .head(20)\n",
    "                )\n",
    "                logger.info(f\"Top LightGBM features:\\n{lgb_importance.to_dicts()}\")\n",
    "                self.mlflow_manager.log_params(\n",
    "                    {\n",
    "                        f\"lgb_top_feature_{idx}\": f\"{row[0]} ({row[1]:.4f})\"\n",
    "                        for idx, row in enumerate(lgb_importance.iter_rows(), start=1)\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                results[\"lightgbm\"] = {\n",
    "                    \"model\": lgb_model,\n",
    "                    \"metrics\": lgb_metrics,\n",
    "                    \"predictions\": lgb_pred,\n",
    "                }\n",
    "            except Exception as lgb_err:\n",
    "                logger.exception(f\"❌ Skipping LightGBM due to error: {lgb_err}\")\n",
    "\n",
    "            # ================================\n",
    "            # ====== Ensemble Training =======\n",
    "            # ================================\n",
    "            # Weighted ensemble based on individual model performance (using validation R2)\n",
    "            # Ensemble: if LightGBM is present, use weighted; otherwise fall back to XGBoost only\n",
    "            xgb_val_pred = xgb_model.predict(X_val)\n",
    "            xgb_val_r2 = r2_score(y_val, xgb_val_pred)\n",
    "\n",
    "            if \"lightgbm\" in results:\n",
    "                lgb_val_pred = results[\"lightgbm\"][\"model\"].predict(X_val)\n",
    "                lgb_val_r2 = r2_score(y_val, lgb_val_pred)\n",
    "\n",
    "                # Calculate weights with a minimum weight constraint\n",
    "                min_weight = 0.2\n",
    "                xgb_weight: float = max(\n",
    "                    min_weight, xgb_val_r2 / (xgb_val_r2 + lgb_val_r2)\n",
    "                )\n",
    "                lgb_weight: float = max(\n",
    "                    min_weight, lgb_val_r2 / (xgb_val_r2 + lgb_val_r2)\n",
    "                )\n",
    "                total_weight = xgb_weight + lgb_weight\n",
    "                xgb_weight /= total_weight\n",
    "                lgb_weight /= total_weight\n",
    "                logger.info(\n",
    "                    f\"⭐ Ensemble weights - XGBoost: {xgb_weight:.3f}, LightGBM: {lgb_weight:.3f}\"\n",
    "                )\n",
    "\n",
    "                ensemble_weights: dict[str, float] = {\n",
    "                    \"xgboost\": xgb_weight,\n",
    "                    \"lightgbm\": lgb_weight,\n",
    "                }\n",
    "                ensemble_pred = (\n",
    "                    xgb_weight * xgb_pred\n",
    "                    + lgb_weight * results[\"lightgbm\"][\"predictions\"]\n",
    "                )\n",
    "                ensemble_models = {\n",
    "                    \"xgboost\": xgb_model,\n",
    "                    \"lightgbm\": results[\"lightgbm\"][\"model\"],\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                logger.info(\"LightGBM not available; using XGBoost-only ensemble\")\n",
    "                ensemble_weights = {\"xgboost\": 1.0}\n",
    "                ensemble_pred = xgb_pred\n",
    "                ensemble_models = {\"xgboost\": xgb_model}\n",
    "\n",
    "            if \"prophet\" in results:\n",
    "                ensemble_models[\"prophet\"] = results[\"prophet\"][\"model\"]\n",
    "                ensemble_weights = {\n",
    "                    \"xgboost\": 1 / 3,\n",
    "                    \"lightgbm\": 1 / 3,\n",
    "                    \"prophet\": 1 / 3,\n",
    "                }\n",
    "\n",
    "            ensemble_model = EnsembleModel(ensemble_models, ensemble_weights)\n",
    "\n",
    "            # Save ensemble model\n",
    "            self.models[\"ensemble\"] = ensemble_model\n",
    "\n",
    "            ensemble_metrics: dict[str, float] = self.calculate_metrics(\n",
    "                y_test, ensemble_pred\n",
    "            )\n",
    "\n",
    "            self.mlflow_manager.log_metrics(\n",
    "                {f\"ensemble_{k}\": v for k, v in ensemble_metrics.items()}\n",
    "            )\n",
    "            self.mlflow_manager.log_model(\n",
    "                ensemble_model, \"ensemble\", input_example=None\n",
    "            )\n",
    "\n",
    "            results[\"ensemble\"] = {\n",
    "                \"model\": ensemble_model,\n",
    "                \"metrics\": ensemble_metrics,\n",
    "                \"predictions\": ensemble_pred,\n",
    "            }\n",
    "\n",
    "            # Run diagnostics\n",
    "            logger.info(\"Running model diagnostics...\")\n",
    "            test_predictions: dict[str, np.ndarray | None] = {\n",
    "                \"xgboost\": xgb_pred if \"xgboost\" in results else None,\n",
    "                \"lightgbm\": lgb_pred if \"lightgbm\" in results else None,\n",
    "                \"ensemble\": ensemble_pred,\n",
    "            }\n",
    "\n",
    "            diagnosis: dict[str, Any] = diagnose_model_performance(\n",
    "                train_df, val_df, test_df, test_predictions, target_col\n",
    "            )\n",
    "\n",
    "            logger.info(\"Diagnostic recommendations:\")\n",
    "            for rec in diagnosis[\"recommendations\"]:\n",
    "                logger.warning(f\"- {rec}\")\n",
    "\n",
    "            # Generate visualizations\n",
    "            logger.info(\"🚨 Generating model comparison visualizations...\")\n",
    "            try:\n",
    "                self._generate_and_log_visualizations(results, test_df)\n",
    "            except Exception as viz_error:\n",
    "                logger.error(\n",
    "                    f\"Visualization generation failed: {viz_error}\", exc_info=True\n",
    "                )\n",
    "\n",
    "            # Save artifacts\n",
    "            self.save_artifacts()\n",
    "\n",
    "            # Get current run ID for verification\n",
    "            current_run_id = mlflow.active_run().info.run_id  # type: ignore\n",
    "\n",
    "            # End MLflow run\n",
    "            self.mlflow_manager.end_run()\n",
    "\n",
    "            logger.info(\"Syncing artifacts to S3...\")\n",
    "            try:\n",
    "                s3_manager = MLflowS3Manager()\n",
    "                s3_manager.sync_mlflow_artifacts_to_s3(current_run_id)\n",
    "                logger.info(\"✅ Successfully synced artifacts to S3\")\n",
    "\n",
    "                # Verify S3 artifacts after sync\n",
    "                logger.info(\"Verifying S3 artifact storage...\")\n",
    "                verification_results = verify_s3_artifacts(\n",
    "                    run_id=current_run_id,\n",
    "                    expected_artifacts=[\n",
    "                        \"models/\",\n",
    "                        \"scalers.pkl\",\n",
    "                        \"encoders.pkl\",\n",
    "                        \"feature_cols.pkl\",\n",
    "                        \"visualizations/\",\n",
    "                        \"reports/\",\n",
    "                    ],\n",
    "                )\n",
    "                log_s3_verification_results(verification_results)\n",
    "\n",
    "                if not verification_results[\"success\"]:\n",
    "                    logger.warning(\"S3 artifact verification failed after sync\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"❌ Failed to sync artifacts to S3: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.mlflow_manager.end_run(status=\"FAILED\")\n",
    "            raise e\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _generate_and_log_visualizations(\n",
    "        self,\n",
    "        results: dict[str, Any],\n",
    "        test_df: pl.DataFrame,\n",
    "        viz_backend: Literal[\"matplotlib\", \"plotly\"] = \"matplotlib\",\n",
    "    ) -> None:\n",
    "        \"\"\"Generate and log model comparison visualizations to MLflow\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting visualization generation...\")\n",
    "            if viz_backend == \"plotly\":\n",
    "                visualizer = ModelVisualizerPlotly()\n",
    "            else:\n",
    "                visualizer = ModelVisualizerMatMatplotlib()\n",
    "\n",
    "            # Extract metrics\n",
    "            metrics_dict: dict[str, Any] = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if \"metrics\" in model_results:\n",
    "                    metrics_dict[model_name] = model_results[\"metrics\"]\n",
    "\n",
    "            # Prepare predictions data\n",
    "            predictions_dict: dict[str, Any] = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if (\n",
    "                    \"predictions\" in model_results\n",
    "                    and model_results[\"predictions\"] is not None\n",
    "                ):\n",
    "                    pred_df: pl.DataFrame = test_df.select([\"date\"]).clone()\n",
    "                    # Visualizer expects a column named 'prediction' (singular)\n",
    "                    pred_df = pred_df.with_columns(\n",
    "                        pl.Series(\"prediction\", values=model_results[\"predictions\"])\n",
    "                    )\n",
    "                    predictions_dict[model_name] = pred_df\n",
    "\n",
    "            # Extract feature importance if available\n",
    "            feature_importance_dict = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if model_name in [\"xgboost\", \"lightgbm\"] and \"model\" in model_results:\n",
    "                    model: Any = model_results[\"model\"]\n",
    "                    if hasattr(model, \"feature_importances_\"):\n",
    "                        importance_df = pl.DataFrame(\n",
    "                            {\n",
    "                                \"feature\": self.feature_cols,\n",
    "                                \"importance\": model.feature_importances_,\n",
    "                            }\n",
    "                        ).sort(\"importance\", descending=True)\n",
    "                        feature_importance_dict[model_name] = importance_df\n",
    "\n",
    "            # Create temporary directory for visualizations\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                logger.info(\n",
    "                    f\"🚨 Creating visualizations in temporary directory: {temp_dir}\"\n",
    "                )\n",
    "\n",
    "                # Generate all visualizations\n",
    "                saved_files = visualizer.create_comprehensive_report(\n",
    "                    metrics_dict=metrics_dict,\n",
    "                    predictions_dict=predictions_dict,\n",
    "                    actual_data=test_df,\n",
    "                    feature_importance_dict=feature_importance_dict\n",
    "                    if feature_importance_dict\n",
    "                    else None,\n",
    "                    save_dir=temp_dir,\n",
    "                )\n",
    "\n",
    "                logger.info(\n",
    "                    f\"✅ Generated {len(saved_files)} visualization files: {list(saved_files.keys())}\"\n",
    "                )\n",
    "\n",
    "                # Log each visualization to MLflow\n",
    "                for viz_name, file_path in saved_files.items():\n",
    "                    if os.path.exists(file_path):\n",
    "                        mlflow.log_artifact(file_path, \"visualizations\")  # type: ignore\n",
    "                        logger.info(\n",
    "                            f\"Logged visualization: {viz_name} from {file_path}\"\n",
    "                        )\n",
    "                    else:\n",
    "                        logger.warning(f\"Visualization file not found: {file_path}\")\n",
    "\n",
    "                # Also create a combined HTML report\n",
    "                self._create_combined_html_report(saved_files, temp_dir)\n",
    "\n",
    "                # Log the combined report\n",
    "                combined_report = os.path.join(temp_dir, \"model_comparison_report.html\")\n",
    "                if os.path.exists(combined_report):\n",
    "                    mlflow.log_artifact(combined_report, \"reports\")  # type: ignore\n",
    "                    logger.info(\"✅ Logged combined HTML report\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Don't fail the entire run\n",
    "            logger.error(f\"❌ Failed to generate visualizations: {e}\")\n",
    "\n",
    "    def _create_combined_html_report(\n",
    "        self, saved_files: dict[str, str], save_dir: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a combined HTML report with all visualizations.\n",
    "\n",
    "        The HTML report includes all visualizations in a single page for easy comparison.\n",
    "        \"\"\"\n",
    "\n",
    "        html_content: str = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Model Comparison Report</title>\n",
    "            <style>\n",
    "                body {{\n",
    "                    font-family: Arial, sans-serif;\n",
    "                    margin: 20px;\n",
    "                    background-color: #f5f5f5;\n",
    "                }}\n",
    "                h1, h2 {{\n",
    "                    color: #333;\n",
    "                }}\n",
    "                .section {{\n",
    "                    background-color: white;\n",
    "                    padding: 20px;\n",
    "                    margin-bottom: 20px;\n",
    "                    border-radius: 8px;\n",
    "                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "                }}\n",
    "                .timestamp {{\n",
    "                    color: #666;\n",
    "                    font-size: 14px;\n",
    "                }}\n",
    "                iframe {{\n",
    "                    width: 100%;\n",
    "                    height: 800px;\n",
    "                    border: 1px solid #ddd;\n",
    "                    border-radius: 4px;\n",
    "                    margin-top: 10px;\n",
    "                }}\n",
    "                img {{\n",
    "                    max-width: 100%;\n",
    "                    height: auto;\n",
    "                    border-radius: 4px;\n",
    "                    margin-top: 10px;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Sales Forecast Model Comparison Report</h1>\n",
    "            <p class=\"timestamp\">Generated on: {timestamp}</p>\n",
    "        \"\"\"\n",
    "\n",
    "        html_content: str = html_content.format(\n",
    "            timestamp=datetime.now().isoformat(timespec=\"seconds\")\n",
    "        )\n",
    "\n",
    "        # Add each visualization section\n",
    "        sections: list[tuple[str, str]] = [\n",
    "            (\"metrics_comparison\", \"Model Performance Metrics\"),\n",
    "            (\"predictions_comparison\", \"Predictions Comparison\"),\n",
    "            (\"residuals_analysis\", \"Residuals Analysis\"),\n",
    "            (\"error_distribution\", \"Error Distribution\"),\n",
    "            (\"feature_importance\", \"Feature Importance\"),\n",
    "            (\"summary\", \"Summary Statistics\"),\n",
    "        ]\n",
    "\n",
    "        for key, title in sections:\n",
    "            if key in saved_files:\n",
    "                html_content += f'<div class=\"section\"><h2>{title}</h2>'\n",
    "\n",
    "                # All files are now PNG - base64 encode them\n",
    "                with open(saved_files[key], \"rb\") as f:\n",
    "                    img_data = base64.b64encode(f.read()).decode()\n",
    "                html_content += (\n",
    "                    f'<img src=\"data:image/png;base64,{img_data}\" alt=\"{title}\">'\n",
    "                )\n",
    "\n",
    "                html_content += \"</div>\"\n",
    "\n",
    "        html_content += \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Save the combined report\n",
    "        with open(os.path.join(save_dir, \"model_comparison_report.html\"), \"w\") as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "    def save_artifacts(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves artifacts to disk in the expected format for MLflow.\n",
    "\n",
    "        Saves the following artifacts:\n",
    "        - scalers.pkl: Joblib dump of the scalers used for feature scaling\n",
    "        - encoders.pkl: Joblib dump of the encoders used for categorical encoding\n",
    "        - feature_cols.pkl: Joblib dump of the feature column names\n",
    "        - models/xgboost/xgboost_model.pkl: Joblib dump of the XGBoost model\n",
    "        - models/lightgbm/lightgbm_model.pkl: Joblib dump of the LightGBM model\n",
    "        - models/ensemble/ensemble_model.pkl: Joblib dump of the ensemble model\n",
    "\n",
    "        Also logs the artifacts to MLflow.\n",
    "        \"\"\"\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts\", exist_ok=True)\n",
    "\n",
    "        joblib.dump(self.scalers, f\"{PACKAGE_PATH}/artifacts/scalers.pkl\")\n",
    "        joblib.dump(self.label_encoders, f\"{PACKAGE_PATH}/artifacts/encoders.pkl\")\n",
    "        joblib.dump(self.feature_cols, f\"{PACKAGE_PATH}/artifacts/feature_cols.pkl\")\n",
    "\n",
    "        # Save individual models in the expected format\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/xgboost\", exist_ok=True)\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/lightgbm\", exist_ok=True)\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/ensemble\", exist_ok=True)\n",
    "\n",
    "        if \"xgboost\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"xgboost\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/xgboost/xgboost_model.pkl\",\n",
    "            )\n",
    "\n",
    "        if \"lightgbm\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"lightgbm\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/lightgbm/lightgbm_model.pkl\",\n",
    "            )\n",
    "\n",
    "        if \"ensemble\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"ensemble\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/ensemble/ensemble_model.pkl\",\n",
    "            )\n",
    "\n",
    "        self.mlflow_manager.log_artifacts(f\"{PACKAGE_PATH}/artifacts\")\n",
    "\n",
    "        logger.info(\"✅ Artifacts saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38954065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23621787",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp: str = \"../../../../Documents/data_dump/bike_data/database.parquet\"\n",
    "# data: pl.DataFrame = pl.read_parquet(fp)\n",
    "# console.print(f\"Shape: {data.shape}\", style=\"info\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152c6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061c811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bike-Rental-Prediction (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

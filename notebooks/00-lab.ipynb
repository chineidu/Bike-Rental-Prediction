{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "236f62b9",
   "metadata": {},
   "source": [
    "# Lab For Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917effb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from typing import Any, Literal\n",
    "\n",
    "import narwhals as nw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from rich.console import Console\n",
    "from rich.theme import Theme\n",
    "\n",
    "custom_theme = Theme(\n",
    "    {\n",
    "        \"white\": \"#FFFFFF\",  # Bright white\n",
    "        \"info\": \"#00FF00\",  # Bright green\n",
    "        \"warning\": \"#FFD700\",  # Bright gold\n",
    "        \"error\": \"#FF1493\",  # Deep pink\n",
    "        \"success\": \"#00FFFF\",  # Cyan\n",
    "        \"highlight\": \"#FF4500\",  # Orange-red\n",
    "    }\n",
    ")\n",
    "console = Console(theme=custom_theme)\n",
    "\n",
    "# Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# NumPy settings\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.display.max_rows = 1_000\n",
    "pd.options.display.max_columns = 1_000\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Polars settings\n",
    "pl.Config.set_fmt_str_lengths(1_000)\n",
    "pl.Config.set_tbl_cols(n=1_000)\n",
    "pl.Config.set_tbl_rows(n=200)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Black code formatter (Optional)\n",
    "%load_ext lab_black\n",
    "\n",
    "# auto reload imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "228c8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def go_up_from_current_directory(*, go_up: int = 1) -> None:\n",
    "    \"\"\"This is used to up a number of directories.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    go_up: int, default=1\n",
    "        This indicates the number of times to go back up from the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import sys\n",
    "\n",
    "    CONST: str = \"../\"\n",
    "    NUM: str = CONST * go_up\n",
    "\n",
    "    # Goto the previous directory\n",
    "    prev_directory = os.path.join(os.path.dirname(__name__), NUM)\n",
    "    # Get the 'absolute path' of the previous directory\n",
    "    abs_path_prev_directory = os.path.abspath(prev_directory)\n",
    "\n",
    "    # Add the path to the System paths\n",
    "    sys.path.insert(0, abs_path_prev_directory)\n",
    "    print(abs_path_prev_directory)\n",
    "\n",
    "\n",
    "# Demo (Prevents ruff from removing the unused module import)\n",
    "name: Any\n",
    "category: Literal[\"A\", \"B\", \"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651f550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mac/Desktop/Projects/Bike-Rental-Prediction\n"
     ]
    }
   ],
   "source": [
    "go_up_from_current_directory(go_up=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6889f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b58149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_or_create_experiment(experiment_name: str) -> str:\n",
    "#     \"\"\"\n",
    "#     Retrieve an MLflow experiment ID for a named experiment.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     experiment_name : str\n",
    "#         Name of the MLflow experiment.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     str\n",
    "#         Identifier of the retrieved or newly created MLflow experiment.\n",
    "#     \"\"\"\n",
    "#     if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "#         return experiment.experiment_id\n",
    "#     return mlflow.create_experiment(experiment_name)\n",
    "\n",
    "\n",
    "# def log_mlflow_artifact(local_path: str, artifact_dest: str | None = None) -> None:\n",
    "#     \"\"\"\n",
    "#     Log a local file as an MLflow artifact.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     local_path : str\n",
    "#         Path to the local file to log.\n",
    "#     artifact_dest : str | None, optional\n",
    "#         Run-relative directory within the MLflow artifact store.\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     FileNotFoundError\n",
    "#         If the provided local path does not exist or is not a file.\n",
    "#     \"\"\"\n",
    "#     file_path = Path(local_path)\n",
    "#     if not file_path.is_file():\n",
    "#         raise FileNotFoundError(f\"Cannot find artifact at {local_path}\")\n",
    "#     mlflow.log_artifact(str(file_path), artifact_path=artifact_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83dabdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5870a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestRegressor</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">100</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;squared_error&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">1.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(123)\n",
    "x = rng.standard_normal(size=(1_000, 10))\n",
    "\n",
    "X_train, X_test = train_test_split(x, test_size=0.2, random_state=123)\n",
    "y_train = rng.standard_normal(size=(X_train.shape[0],))\n",
    "y_test = rng.standard_normal(size=(X_test.shape[0],))\n",
    "\n",
    "params: dict[str, Any] = {\n",
    "    \"n_estimators\": 100,\n",
    "    \"max_depth\": 10,\n",
    "}\n",
    "\n",
    "rf_reg = RandomForestRegressor(**params)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "# rf_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccca7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "port: int = 6060\n",
    "url: str = f\"http://0.0.0.0:{port}\"\n",
    "\n",
    "mlflow.set_tracking_uri(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "88c1bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name: str = \"Demo Experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c39f5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "import joblib\n",
    "import mlflow\n",
    "import yaml\n",
    "\n",
    "\n",
    "def log_mlflow_artifact_v1(local_path: str, artifact_dest: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Log a local file to MLflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_path : str\n",
    "        Path to the local file to log.\n",
    "    artifact_dest : str | None\n",
    "        (Optional) Run-relative directory in the MLflow artifact store.\n",
    "    \"\"\"\n",
    "    if not isinstance(local_path, Path):\n",
    "        file_path = Path(local_path)\n",
    "    if not file_path.is_file():\n",
    "        raise FileNotFoundError(f\"Cannot find artifact at {local_path}\")\n",
    "    # Log it under artifact_dest (or root if None)\n",
    "    mlflow.log_artifact(str(file_path), artifact_path=artifact_dest)\n",
    "\n",
    "\n",
    "def _get_run_name(run_name: str | None = None) -> str:\n",
    "    if run_name is None:\n",
    "        run_name = f\"run_{datetime.now().isoformat(timespec='seconds')}\"\n",
    "    return run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de8dffd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/vv/g_5scsqs6fj18dr1q_bww19r0000gn/T/tmpzxyrleyl/my_file.json\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    my_path = Path(tmpdir, \"my_file.json\")\n",
    "    print(my_path)\n",
    "    with open(my_path, \"w\") as f:\n",
    "        json.dump({\"name\": \"wuraola\", \"role\": \"medical doctor\"}, fp=f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f55e26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Callable\n",
    "\n",
    "type WriteFn = Callable[[Any, Path], None]\n",
    "\n",
    "\n",
    "class ArtifactsType(str, Enum):\n",
    "    JSON = \"json\"\n",
    "    TXT = \"txt\"\n",
    "    YAML = \"yaml\"\n",
    "    ANY = \"joblib\"\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return str(self.value)\n",
    "\n",
    "\n",
    "def write_json(object: dict[str, Any] | Any, filepath: Path, indent: int = 2) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        json.dump(object, fp=f, indent=indent)\n",
    "\n",
    "\n",
    "def write_txt(object: list[Any], filepath: Path) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        for line in object:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "\n",
    "def write_yaml(object: dict[str, Any] | Any, filepath: Path) -> None:\n",
    "    with open(filepath, \"w\") as f:\n",
    "        yaml.dump(object, f)\n",
    "\n",
    "\n",
    "def write_pickle(object: dict[str, Any] | Any, filepath: Path) -> None:\n",
    "    joblib.dump(object, filepath)\n",
    "\n",
    "\n",
    "def log_mlflow_artifact(\n",
    "    object: Any,\n",
    "    object_type: ArtifactsType,\n",
    "    filename: str,\n",
    "    artifact_dest: str | None = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Log a local file to MLflow.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    local_path : str\n",
    "        Path to the local file to log.\n",
    "    artifact_dest : str | None\n",
    "        (Optional) Run-relative directory in the MLflow artifact store.\n",
    "    \"\"\"\n",
    "    if object_type == ArtifactsType.JSON:\n",
    "        write_fn = write_json\n",
    "    elif object_type == ArtifactsType.TXT:\n",
    "        write_fn = write_txt\n",
    "    elif object_type == ArtifactsType.YAML:\n",
    "        write_fn = write_yaml\n",
    "    elif object_type == ArtifactsType.ANY:\n",
    "        write_fn = write_pickle\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported object type: {object_type}\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        tmp_path = Path(tmpdir) / f\"{filename}-artifact.{object_type}\"\n",
    "        write_fn(object, tmp_path)\n",
    "        mlflow.log_artifact(tmp_path, artifact_path=artifact_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7636eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_mlflow_artifact(\n",
    "    object={\"name\": \"wuraola\", \"role\": \"medical doctor\"},\n",
    "    object_type=ArtifactsType.JSON,\n",
    "    filename=\"my_metadata\",\n",
    "    artifact_dest=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b072823",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_l: list[str] = [\"It is good to be good, '25000'\", \"thank you Lord, '45294'\"]\n",
    "dt_l: dict[str, Any] = {\"name\": \"my name\"}\n",
    "write_pickle(dt_l, \"file.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc2776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/02 13:08:45 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run run_2025-10-02T13:08:43 at: http://0.0.0.0:6060/#/experiments/767392527681543348/runs/a84f7d5da017465fa64e425604bd17e1\n",
      "ðŸ§ª View experiment at: http://0.0.0.0:6060/#/experiments/767392527681543348\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "with mlflow.start_run(run_name=_get_run_name()) as run:\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(sk_model=rf_reg, input_example=X_test, name=\"rf_reg\")\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics(\n",
    "        {\"mse\": 45.0, \"rmse\": 5.0, \"mae\": 4.0, \"r2\": 0.8, \"msle\": 0.1, \"medae\": 3.0}\n",
    "    )\n",
    "\n",
    "    # Log the hyperparameter\n",
    "    mlflow.log_params(params=params)\n",
    "\n",
    "    # Log plots\n",
    "    # mlflow.log_figure(fig1, \"time_series_demand.png\")\n",
    "    # mlflow.log_figure(fig2, \"box_weekend.png\")\n",
    "\n",
    "    # Log artifacts saved in the local file system\n",
    "    log_mlflow_artifact(\"./plots/correlation_wf_target.png\", artifact_dest=\"plots\")\n",
    "    # log_mlflow_artifact(\"./my_metadata.json\", artifact_dest=\"metadata\")\n",
    "    log_mlflow_artifact(\n",
    "        object={\"name\": \"wuraola\", \"role\": \"medical doctor\"},\n",
    "        object_type=ArtifactsType.YAML,\n",
    "        filename=\"my_metadata\",\n",
    "        artifact_dest=None,\n",
    "    )\n",
    "#"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b9ba3ed",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\"\"\"This module provides utilities for managing MLflow artifacts in S3/MinIO.\n",
    "Inspired by: https://github.com/airscholar/astro-salesforecast/blob/main/include/utils/mlflow_utils.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from mlflow.pyfunc import PyFuncModel\n",
    "from mlflow.tracking import MlflowClient  # type: ignore\n",
    "\n",
    "from include import create_logger\n",
    "from include.config import app_config\n",
    "from include.utilities.service_discovery import get_mlflow_endpoint\n",
    "\n",
    "logger = create_logger(__name__)\n",
    "\n",
    "\n",
    "class MLflowManager:\n",
    "    def __init__(self) -> None:\n",
    "        mlflow_config = app_config.mlflow\n",
    "        self.tracking_uri = get_mlflow_endpoint()\n",
    "\n",
    "        self.experiment_name = mlflow_config.experiment_name\n",
    "        self.registry_name = mlflow_config.registry_name\n",
    "\n",
    "        mlflow.set_tracking_uri(self.tracking_uri)\n",
    "\n",
    "        try:\n",
    "            mlflow.set_experiment(self.experiment_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to set experiment {self.experiment_name}: {e}\")\n",
    "\n",
    "        self.client = MlflowClient(tracking_uri=self.tracking_uri)\n",
    "\n",
    "    def get_run_id(self, run_name: str | None = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate a unique run ID for an MLflow run.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        run_name : str, optional\n",
    "            If provided, the generated run ID will be prefixed with this string.\n",
    "            If not provided, a default name will be generated.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Unique run ID to be used for MLflow experiments.\n",
    "        \"\"\"\n",
    "        if run_name is None:\n",
    "            run_name = f\"run_{datetime.now().isoformat(timespec='seconds')}\"\n",
    "        return run_name\n",
    "\n",
    "    def start_run(\n",
    "        self, run_name: str | None = None, tags: dict[str, str] | None = None\n",
    "    ) -> str:\n",
    "        \"\"\"\n",
    "        Start a new MLflow run.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        run_name : str, optional\n",
    "            Name of the run to start. If not provided, a default name will be generated.\n",
    "        tags : dict[str, str], optional\n",
    "            Tags to be added to the run.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            ID of the started run.\n",
    "        \"\"\"\n",
    "        run_name = self.get_run_id(run_name)\n",
    "\n",
    "        run = mlflow.start_run(run_name=run_name, tags=tags)  # type: ignore\n",
    "        logger.info(f\"Started MLflow run: {run.info.run_id}\")\n",
    "        return run.info.run_id\n",
    "\n",
    "    def log_params(self, params: dict[str, Any]) -> None:\n",
    "        \"\"\"\n",
    "        Log parameters to MLflow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict[str, Any]\n",
    "            Parameters to log.\n",
    "        \"\"\"\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)  # type: ignore\n",
    "\n",
    "    def log_metrics(self, metrics: dict[str, float], step: int | None = None) -> None:\n",
    "        \"\"\"Log metrics to MLflow.\"\"\"\n",
    "        for key, value in metrics.items():\n",
    "            mlflow.log_metric(key, value, step=step)  # type: ignore\n",
    "\n",
    "    def log_model(\n",
    "        self,\n",
    "        model: Any,\n",
    "        model_name: str,\n",
    "        input_example: pd.DataFrame | None = None,  # noqa: ARG002\n",
    "        signature: Any | None = None,  # noqa: ARG002\n",
    "        registered_model_name: str | None = None,  # noqa: ARG002\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Log model to MLflow with compatibility for different versions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model : Any\n",
    "            Model to log.\n",
    "        model_name : str\n",
    "            Name of the model to log.\n",
    "        input_example : pd.DataFrame, optional\n",
    "            Example input to be used for logging model signature.\n",
    "        signature : Any, optional\n",
    "            Model signature to be used for logging.\n",
    "        registered_model_name : str, optional\n",
    "            Name of the registered model to log.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Falls back to saving models as artifacts if MLflow model logging fails.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Save model to a temporary file first\n",
    "            import tempfile\n",
    "\n",
    "            with tempfile.TemporaryDirectory() as tmpdir:\n",
    "                model_path = os.path.join(tmpdir, f\"{model_name}_model.pkl\")\n",
    "                metadata_path = os.path.join(tmpdir, f\"{model_name}_metadata.yaml\")\n",
    "\n",
    "                # Save model\n",
    "                joblib.dump(model, model_path)\n",
    "\n",
    "                # Create metadata\n",
    "                metadata = {\n",
    "                    \"model_type\": model_name,\n",
    "                    \"framework\": type(model).__module__,\n",
    "                    \"class\": type(model).__name__,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                }\n",
    "                with open(metadata_path, \"w\") as f:\n",
    "                    yaml.dump(metadata, f)\n",
    "\n",
    "                # Log artifacts\n",
    "                mlflow.log_artifact(model_path, artifact_path=f\"models/{model_name}\")  # type: ignore\n",
    "                mlflow.log_artifact(metadata_path, artifact_path=f\"models/{model_name}\")  # type: ignore\n",
    "\n",
    "                logger.info(f\"âœ… Successfully saved {model_name} model as artifact\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"âŒ Failed to log model {model_name}: {e}\")\n",
    "\n",
    "    def log_artifacts(self, artifact_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Log artifacts to MLflow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        artifact_path : str\n",
    "            Local path to the artifacts to log.\n",
    "        \"\"\"\n",
    "        mlflow.log_artifacts(artifact_path)  # type: ignore\n",
    "\n",
    "    def log_figure(self, figure: Any, artifact_file: str) -> None:\n",
    "        \"\"\"\n",
    "        Log a figure to MLflow.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        figure : Any\n",
    "            Figure to log. Can be a matplotlib figure, plotly figure, bokeh\n",
    "            figure, or altair chart.\n",
    "        artifact_file : str\n",
    "            Local file path used to write the figure to. The file will be saved\n",
    "            to the MLflow artifact directory.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        See the `mlflow.log_figure` documentation for more information.\n",
    "        \"\"\"\n",
    "        mlflow.log_figure(figure, artifact_file)  # type: ignore\n",
    "\n",
    "    def end_run(self, status: str = \"FINISHED\") -> None:\n",
    "        \"\"\"\n",
    "        End the current MLflow run.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        status : str\n",
    "            Status to end the run with. Defaults to \"FINISHED\".\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        If the run is successful, the artifacts will be synced to S3.\n",
    "        \"\"\"\n",
    "        # Get run ID before ending\n",
    "        run = mlflow.active_run()\n",
    "        run_id = run.info.run_id if run else None\n",
    "\n",
    "        mlflow.end_run(status=status)  # type: ignore\n",
    "        logger.info(\"ðŸš¨ Ended MLflow run\")\n",
    "\n",
    "        # Sync artifacts to S3 after run ends\n",
    "        if run_id and status == \"FINISHED\":\n",
    "            try:\n",
    "                from include.utilities.mlflow_s3_utils import MLflowS3Manager\n",
    "\n",
    "                s3_manager = MLflowS3Manager()\n",
    "                s3_manager.sync_mlflow_artifacts_to_s3(run_id)\n",
    "                logger.info(f\"âœ… Synced artifacts to S3 for run {run_id}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"âŒ Failed to sync artifacts to S3: {e}\")\n",
    "\n",
    "    def get_best_model(\n",
    "        self, metric: str = \"rmse\", ascending: bool = True\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the best model based on a specified metric from the experiment\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric : str\n",
    "            Metric to use for selecting the best model. Defaults to \"rmse\".\n",
    "        ascending : bool\n",
    "            Whether to sort the runs in ascending or descending order based on the specified metric.\n",
    "            Defaults to True.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict[str, Any]\n",
    "            A dictionary containing the best run's ID, metrics, and parameters.\n",
    "        \"\"\"\n",
    "        experiment = mlflow.get_experiment_by_name(self.experiment_name)  # type: ignore\n",
    "        runs = mlflow.search_runs(  # type: ignore\n",
    "            experiment_ids=[experiment.experiment_id],  # type: ignore\n",
    "            order_by=[f\"metrics.{metric} {'ASC' if ascending else 'DESC'}\"],\n",
    "            max_results=1,\n",
    "        )\n",
    "\n",
    "        if len(runs) == 0:\n",
    "            raise ValueError(\"No runs found in the experiment\")\n",
    "\n",
    "        best_run = runs.iloc[0]  # type: ignore\n",
    "        return {\n",
    "            \"run_id\": best_run[\"run_id\"],\n",
    "            \"metrics\": {\n",
    "                col.replace(\"metrics.\", \"\"): val\n",
    "                for col, val in best_run.items()\n",
    "                if col.startswith(\"metrics.\")\n",
    "            },\n",
    "            \"params\": {\n",
    "                col.replace(\"params.\", \"\"): val\n",
    "                for col, val in best_run.items()\n",
    "                if col.startswith(\"params.\")\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_uri: str) -> PyFuncModel | Any:\n",
    "        \"\"\"\n",
    "        Load model from MLflow or from artifacts.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_uri : str\n",
    "            URI of the model to load.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        PyFuncModel | Any\n",
    "            Loaded model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "        except Exception:\n",
    "            # Try loading from artifacts\n",
    "            if \"runs:/\" in model_uri:\n",
    "                run_id = model_uri.split(\"/\")[1]\n",
    "                artifact_path = \"/\".join(model_uri.split(\"/\")[2:])\n",
    "                local_path = mlflow.artifacts.download_artifacts(\n",
    "                    run_id=run_id, artifact_path=f\"{artifact_path}_model.pkl\"\n",
    "                )  # type: ignore\n",
    "                return joblib.load(local_path)\n",
    "\n",
    "            raise ValueError(f\"âŒ Cannot load model from {model_uri}\") from None\n",
    "\n",
    "    def register_model(self, run_id: str, model_name: str, artifact_path: str) -> str:\n",
    "        \"\"\"\n",
    "        Register model if possible, otherwise return run_id as version.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        run_id : str\n",
    "            MLflow run ID containing the model to register.\n",
    "        model_name : str\n",
    "            Name to give the registered model.\n",
    "        artifact_path : str\n",
    "            Path to the model artifact within the run.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Version of the registered model, or the run_id if registration failed.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            model_uri = f\"runs:/{run_id}/{artifact_path}\"\n",
    "            model_version = mlflow.register_model(\n",
    "                model_uri, f\"{self.registry_name}_{model_name}\"\n",
    "            )  # type: ignore\n",
    "            return model_version.version\n",
    "        except Exception:\n",
    "            logger.warning(\n",
    "                \"âŒ Model registration not available, using run_id as version\"\n",
    "            )\n",
    "            return run_id\n",
    "\n",
    "    def transition_model_stage(self, model_name: str, version: str, stage: str) -> None:\n",
    "        \"\"\"\n",
    "        Transition model to a new stage.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the model to transition.\n",
    "        version : str\n",
    "            Version of the model to transition.\n",
    "        stage : str\n",
    "            Name of the stage to transition to.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.client.transition_model_version_stage(\n",
    "                name=f\"{self.registry_name}_{model_name}\", version=version, stage=stage\n",
    "            )\n",
    "        except Exception:\n",
    "            logger.warning(\"âŒ Model stage transition not available\")\n",
    "\n",
    "    def get_latest_model_version(\n",
    "        self, model_name: str, stage: str | None = None\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get the latest model version from the registry.\n",
    "\n",
    "        If the model is not found, fall back to finding the best run.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        model_name : str\n",
    "            Name of the model to retrieve.\n",
    "        stage : str | None\n",
    "            Optional - stage to filter the model versions by.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict[str, Any]\n",
    "            A dictionary containing the version, stage, run_id and source of the model.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            filter_string = f\"name='{self.registry_name}_{model_name}'\"\n",
    "            if stage:\n",
    "                filter_string += f\" AND current_stage='{stage}'\"\n",
    "\n",
    "            versions = self.client.search_model_versions(filter_string)\n",
    "            if not versions:\n",
    "                raise ValueError(f\"No model versions found for {model_name}\")\n",
    "\n",
    "            # Find the latest model version\n",
    "            latest_version = max(versions, key=lambda x: int(x.version))\n",
    "            return {\n",
    "                \"version\": latest_version.version,\n",
    "                \"stage\": latest_version.current_stage,\n",
    "                \"run_id\": latest_version.run_id,\n",
    "                \"source\": latest_version.source,\n",
    "            }\n",
    "        except Exception:\n",
    "            logger.debug(\n",
    "                \"No model versions found in the registry, falling back to finding the best run\"\n",
    "            )\n",
    "            # Fallback to finding the best run\n",
    "            best_model = self.get_best_model()\n",
    "\n",
    "            return {\n",
    "                \"version\": best_model[\"run_id\"],\n",
    "                \"stage\": \"None\",\n",
    "                \"run_id\": best_model[\"run_id\"],\n",
    "                \"source\": f\"runs:/{best_model['run_id']}/models\",\n",
    "            }"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26bc72c5",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\"\"\"This module provides utilities for model training.\n",
    "Inspired by: https://github.com/airscholar/astro-salesforecast/blob/main/include/ml_models/train_models.py\n",
    "\"\"\"\n",
    "\n",
    "import base64\n",
    "import json\n",
    "import tempfile\n",
    "from typing import Any, Literal\n",
    "\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from include import PACKAGE_PATH, create_logger\n",
    "from include.ml.diagnostics import diagnose_model_performance\n",
    "from include.ml.ensemble_model import EnsembleModel\n",
    "from include.ml.visualization import ModelVisualizerMatMatplotlib, ModelVisualizerPlotly\n",
    "from include.utilities.feature_engineering import FeatureEngineer\n",
    "from include.utilities.mlflow_s3_utils import MLflowS3Manager\n",
    "from include.utilities.mlflow_utils import MLflowManager\n",
    "from include.utilities.s3_verification import (\n",
    "    log_s3_verification_results,\n",
    "    verify_s3_artifacts,\n",
    ")\n",
    "\n",
    "logger = create_logger(__name__)\n",
    "\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"\n",
    "        Initializes a ModelTrainer object.\n",
    "\n",
    "        The ModelTrainer object is used to train and diagnose the performance of\n",
    "        machine learning models.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        model_config : ModelsConfig\n",
    "            MLflow models configuration\n",
    "        training_config : TrainingConfig\n",
    "            Training configuration\n",
    "        mlflow_manager : MLflowManager\n",
    "            Manager for MLflow\n",
    "        feature_engineer : FeatureEngineer\n",
    "            Feature engineering utilities\n",
    "        models : dict[str, Any]\n",
    "            Trained models\n",
    "        scalers : dict[str, StandardScaler]\n",
    "            Scalers used for feature scaling\n",
    "        label_encoders : dict[str, LabelEncoder]\n",
    "            Label encoders used for categorical encoding\n",
    "        \"\"\"\n",
    "        self.model_config = app_config.models\n",
    "        self.training_config = app_config.training\n",
    "        self.mlflow_manager = MLflowManager()\n",
    "        self.feature_engineer = FeatureEngineer()\n",
    "        self.models: dict[str, Any] = {}\n",
    "        self.scalers: dict[str, StandardScaler] = {}\n",
    "        self.label_encoders: dict[str, LabelEncoder] = {}\n",
    "\n",
    "    @property\n",
    "    def run_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Property to get the run name.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Run name.\n",
    "        \"\"\"\n",
    "        return self.mlflow_manager.get_run_id(None)\n",
    "\n",
    "    def prepare_data(\n",
    "        self,\n",
    "        df: pl.DataFrame,\n",
    "        target_col: str = \"sales\",\n",
    "        group_cols: list[str] | None = None,\n",
    "        categorical_cols: list[str] | None = None,\n",
    "    ) -> tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]:\n",
    "        \"\"\"\n",
    "        Prepare data for training and validation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pl.DataFrame\n",
    "            Input DataFrame.\n",
    "        target_col : str, optional\n",
    "            Target column name. Defaults to \"sales\".\n",
    "        group_cols : list[str] | None, optional\n",
    "            Columns to group by when creating lag and rolling features. Defaults to None.\n",
    "        categorical_cols : list[str] | None, optional\n",
    "            Columns to create interaction features for. Defaults to None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[pl.DataFrame, pl.DataFrame, pl.DataFrame]\n",
    "            Tuple of (train_df, val_df, test_df) DataFrames.\n",
    "        \"\"\"\n",
    "        required_cols: list[str] = [\"date\", target_col]\n",
    "        if group_cols:\n",
    "            required_cols.extend(group_cols)\n",
    "\n",
    "        missing_cols: list[str] = list(set(required_cols) - set(df.columns))\n",
    "        if missing_cols:\n",
    "            raise ValueError(\n",
    "                f\"âŒ Missing required columns for training: {missing_cols}\"\n",
    "            )\n",
    "\n",
    "        # Feature engineering\n",
    "        df_features: pl.DataFrame = self.feature_engineer.create_all_features(\n",
    "            df,\n",
    "            target_col=target_col,\n",
    "            date_col=\"date\",\n",
    "            group_cols=group_cols,\n",
    "            categorical_cols=categorical_cols,\n",
    "        )\n",
    "        # Sort the data chronologically (for time series)\n",
    "        df_features = df_features.sort(by=[\"date\"], descending=False)\n",
    "\n",
    "        # Split data: Use the most recent data for validation (mimick real-world scenario)\n",
    "        train_size: int = int(\n",
    "            len(df_features)\n",
    "            * (\n",
    "                1\n",
    "                - self.training_config.test_size\n",
    "                - self.training_config.validation_size\n",
    "            )\n",
    "        )\n",
    "        validation_size: int = int(\n",
    "            len(df_features) * self.training_config.validation_size\n",
    "        )\n",
    "\n",
    "        # Drop rows with NaN in target column\n",
    "        train_df: pl.DataFrame = df_features[:train_size].drop_nulls(\n",
    "            subset=[target_col]\n",
    "        )\n",
    "        val_df: pl.DataFrame = df_features[\n",
    "            train_size : train_size + validation_size\n",
    "        ].drop_nulls(subset=[target_col])\n",
    "        test_df: pl.DataFrame = df_features[train_size + validation_size :].drop_nulls(\n",
    "            subset=[target_col]\n",
    "        )\n",
    "        extras: dict[str, Any] = {\n",
    "            \"train_size\": train_size,\n",
    "            \"validation_size\": validation_size,\n",
    "            \"test_size\": len(test_df),\n",
    "        }\n",
    "        logger.info(f\"Data split - {json.dumps(extras)}\")\n",
    "\n",
    "        return train_df, val_df, test_df\n",
    "\n",
    "    def preprocess_features(\n",
    "        self,\n",
    "        train_df: pl.DataFrame,\n",
    "        val_df: pl.DataFrame,\n",
    "        test_df: pl.DataFrame,\n",
    "        target_col: str,\n",
    "        excluded_cols: list[str] = [\"date\"],  # noqa: B006\n",
    "    ) -> tuple[\n",
    "        pl.DataFrame, pl.DataFrame, pl.DataFrame, pl.Series, pl.Series, pl.Series\n",
    "    ]:\n",
    "        # Separate features and target\n",
    "        \"\"\"\n",
    "        Preprocess features for training and evaluation.\n",
    "\n",
    "        This function separates features and target from the input DataFrame, encodes\n",
    "        categorical features using LabelEncoder, and scales the features using StandardScaler.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pl.DataFrame\n",
    "            Training data.\n",
    "        val_df : pl.DataFrame\n",
    "            Validation data.\n",
    "        test_df : pl.DataFrame\n",
    "            Testing data.\n",
    "        target_col : str\n",
    "            Target column name.\n",
    "        excluded_cols : list[str]\n",
    "            Columns to exclude from the feature set. Defaults to [\"date\"].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_train_scaled : pl.DataFrame\n",
    "            Scaled training features.\n",
    "        X_val_scaled : pl.DataFrame\n",
    "            Scaled validation features.\n",
    "        X_test_scaled : pl.DataFrame\n",
    "            Scaled testing features.\n",
    "        y_train : pl.Series\n",
    "            Training target.\n",
    "        y_val : pl.Series\n",
    "            Validation target.\n",
    "        y_test : pl.Series\n",
    "            Testing target.\n",
    "        \"\"\"\n",
    "        X_train: pl.DataFrame = train_df.drop([target_col] + excluded_cols)\n",
    "        X_val: pl.DataFrame = val_df.drop([target_col] + excluded_cols)\n",
    "        X_test: pl.DataFrame = test_df.drop([target_col] + excluded_cols)\n",
    "\n",
    "        y_train: pl.Series = train_df[target_col]\n",
    "        y_val: pl.Series = val_df[target_col]\n",
    "        y_test: pl.Series = test_df[target_col]\n",
    "\n",
    "        # Encode categorical features\n",
    "        # Note: sklearn's LabelEncoder raises on unseen labels. We map unseen labels to -1\n",
    "        # so validation/test data won't break the pipeline. We keep encoders in\n",
    "        # self.label_encoders to reuse during inference.\n",
    "        cat_cols: list[str] = X_train.select(cs.string()).columns\n",
    "        for var in cat_cols:\n",
    "            train_values = X_train[var].to_list()\n",
    "\n",
    "            if var not in self.label_encoders:\n",
    "                le = LabelEncoder()\n",
    "                encoded_train = le.fit_transform(train_values)\n",
    "                self.label_encoders[var] = le\n",
    "            else:\n",
    "                le = self.label_encoders[var]\n",
    "                try:\n",
    "                    encoded_train = le.transform(train_values)\n",
    "                except ValueError:\n",
    "                    mapping = {c: i for i, c in enumerate(le.classes_)}\n",
    "                    encoded_train = [mapping.get(v, -1) for v in train_values]\n",
    "\n",
    "            # Build mapping for known classes to safely encode val/test (unknown -> -1)\n",
    "            mapping = {c: i for i, c in enumerate(self.label_encoders[var].classes_)}\n",
    "\n",
    "            def _encode_list(\n",
    "                values: list[str], mapping: dict[str, int] = mapping\n",
    "            ) -> list[int]:\n",
    "                \"\"\"Encode a list of categorical values using an existing mapping.\"\"\"\n",
    "                return [mapping.get(v, -1) for v in values]\n",
    "\n",
    "            val_values: list[Any] = X_val[var].to_list()\n",
    "            test_values: list[Any] = X_test[var].to_list()\n",
    "\n",
    "            encoded_val: list[int] = _encode_list(val_values)\n",
    "            encoded_test: list[int] = _encode_list(test_values)\n",
    "\n",
    "            # Attach encoded columns back as small-int (Int8). -1 reserved for unknowns.\n",
    "            X_train = X_train.with_columns(\n",
    "                pl.Series(var, values=encoded_train, dtype=pl.Int8)\n",
    "            )\n",
    "            X_val = X_val.with_columns(\n",
    "                pl.Series(var, values=encoded_val, dtype=pl.Int8)\n",
    "            )\n",
    "            X_test = X_test.with_columns(\n",
    "                pl.Series(var, values=encoded_test, dtype=pl.Int8)\n",
    "            )\n",
    "\n",
    "        # Track feature columns used for modeling (post-encoding, pre-scaling)\n",
    "        self.feature_cols: list[str] = X_train.columns  # type: ignore[attr-defined]\n",
    "\n",
    "        # Scale the features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.fit_transform(X_train), schema=X_train.columns\n",
    "        )\n",
    "        X_val_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.transform(X_val), schema=X_val.columns\n",
    "        )\n",
    "        X_test_scaled: pl.DataFrame = pl.DataFrame(\n",
    "            scaler.transform(X_test), schema=X_test.columns\n",
    "        )\n",
    "\n",
    "        self.scalers[\"standard\"] = scaler\n",
    "\n",
    "        return (X_train_scaled, X_val_scaled, X_test_scaled, y_train, y_val, y_test)\n",
    "\n",
    "    def calculate_metrics(\n",
    "        self, y_true: np.ndarray, y_pred: np.ndarray\n",
    "    ) -> dict[str, float]:\n",
    "        \"\"\"\n",
    "        Calculate and return a dictionary with the following metrics:\n",
    "        - root mean squared error (rmse)\n",
    "        - mean absolute error (mae)\n",
    "        - mean absolute percentage error (mape)\n",
    "        - R-squared (r2)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y_true : np.ndarray\n",
    "            True labels.\n",
    "        y_pred : np.ndarray\n",
    "            Predicted labels.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        metrics : dict[str, float]\n",
    "            Dictionary with the calculated metrics.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"rmse\": np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            \"mae\": mean_absolute_error(y_true, y_pred),\n",
    "            \"mape\": np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "            \"r2\": r2_score(y_true, y_pred),\n",
    "        }\n",
    "\n",
    "    def train_xgboost(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "    ) -> xgb.XGBRegressor:  # type: ignore\n",
    "        \"\"\"\n",
    "        Train an XGBoost model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Training features.\n",
    "        y_train : np.ndarray\n",
    "            Training target.\n",
    "        X_val : np.ndarray\n",
    "            Validation features.\n",
    "        y_val : np.ndarray\n",
    "            Validation target.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : xgboost.XGBRegressor\n",
    "            Trained model.\n",
    "\n",
    "        \"\"\"\n",
    "        logger.info(\"Training XGBoost model\")\n",
    "\n",
    "        best_params = self.model_config.xgboost.params\n",
    "        best_params[\"early_stopping_rounds\"] = 50\n",
    "        model = xgb.XGBRegressor(**best_params)  # type: ignore\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "        self.models[\"xgboost\"] = model\n",
    "        return model\n",
    "\n",
    "    def train_lightgbm(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        y_train: np.ndarray,\n",
    "        X_val: np.ndarray,\n",
    "        y_val: np.ndarray,\n",
    "    ) -> lgb.LGBMRegressor:  # type: ignore\n",
    "        \"\"\"\n",
    "        Train a LightGBM model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : np.ndarray\n",
    "            Training features.\n",
    "        y_train : np.ndarray\n",
    "            Training target.\n",
    "        X_val : np.ndarray\n",
    "            Validation features.\n",
    "        y_val : np.ndarray\n",
    "            Validation target.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model : lgb.LGBMRegressor\n",
    "            Trained model.\n",
    "        \"\"\"\n",
    "        logger.info(\"Training LightGBM model\")\n",
    "\n",
    "        # Access model config using attribute access (ModelsConfig Pydantic model)\n",
    "        best_params = self.model_config.lightgbm.params\n",
    "\n",
    "        model = lgb.LGBMRegressor(**best_params)  # type: ignore\n",
    "\n",
    "        # Use sklearn-compatible early stopping parameter to avoid callback API differences\n",
    "        # This is compatible with scikit-learn API wrapper for LightGBM\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(50)],\n",
    "        )\n",
    "\n",
    "        self.models[\"lightgbm\"] = model\n",
    "        return model\n",
    "\n",
    "    def train_all_models(\n",
    "        self,\n",
    "        train_df: pl.DataFrame,\n",
    "        val_df: pl.DataFrame,\n",
    "        test_df: pl.DataFrame,\n",
    "        target_col: str = \"sales\",\n",
    "    ) -> dict[str, dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Train multiple models (XGBoost, LightGBM, and Prophet (optional)) on the given data, and\n",
    "        log the results to MLflow. The models are trained on the training data, and evaluated on\n",
    "        the validation data. The best model is selected based on the validation R2 score, and the\n",
    "        ensemble model is created using the best model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        train_df : pl.DataFrame\n",
    "            Training data.\n",
    "        val_df : pl.DataFrame\n",
    "            Validation data.\n",
    "        test_df : pl.DataFrame\n",
    "            Testing data.\n",
    "        target_col : str, optional\n",
    "            Target column name, by default \"sales\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        results : dict[str, dict[str, Any]]\n",
    "            A dictionary containing the results of the model training, including the trained models,\n",
    "            the metrics, and the predictions.\n",
    "        \"\"\"\n",
    "        results: dict[str, dict[str, Any]] = {}\n",
    "\n",
    "        # Start MLflow run\n",
    "        _ = self.mlflow_manager.start_run(\n",
    "            run_name=f\"{app_config.mlflow.experiment_name}_training_{datetime.now().isoformat(timespec='seconds')}\",\n",
    "            tags={\"model_type\": \"ensemble\"},\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            # Preprocess data\n",
    "            (\n",
    "                X_train_df,\n",
    "                X_val_df,\n",
    "                X_test_df,\n",
    "                y_train_series,\n",
    "                y_val_series,\n",
    "                y_test_series,\n",
    "            ) = self.preprocess_features(train_df, val_df, test_df, target_col)\n",
    "            # Convert to Arrays\n",
    "            X_train: np.ndarray = X_train_df.to_numpy()\n",
    "            X_val: np.ndarray = X_val_df.to_numpy()\n",
    "            X_test: np.ndarray = X_test_df.to_numpy()\n",
    "            y_train: np.ndarray = y_train_series.to_numpy()\n",
    "            y_val: np.ndarray = y_val_series.to_numpy()\n",
    "            y_test: np.ndarray = y_test_series.to_numpy()\n",
    "\n",
    "            # Log data stats\n",
    "            self.mlflow_manager.log_params(\n",
    "                {\n",
    "                    \"train_size\": len(train_df),\n",
    "                    \"val_size\": len(val_df),\n",
    "                    \"test_size\": len(test_df),\n",
    "                    \"n_features\": X_train.shape[1],\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # ================================\n",
    "            # ======= XGBoost Training =======\n",
    "            # ================================\n",
    "            xgb_model = self.train_xgboost(X_train, y_train, X_val, y_val)\n",
    "            xgb_pred = xgb_model.predict(X_test)\n",
    "            xgb_metrics = self.calculate_metrics(y_test, xgb_pred)\n",
    "\n",
    "            self.mlflow_manager.log_metrics(\n",
    "                {f\"xgboost_{k}\": v for k, v in xgb_metrics.items()}\n",
    "            )\n",
    "            self.mlflow_manager.log_model(\n",
    "                xgb_model, \"xgboost\", input_example=X_train_df.head()\n",
    "            )\n",
    "\n",
    "            # Log feature importance\n",
    "            feature_importance: pl.DataFrame = (\n",
    "                pl.DataFrame(\n",
    "                    {\n",
    "                        \"feature\": self.feature_cols,\n",
    "                        \"importance\": xgb_model.feature_importances_,\n",
    "                    }\n",
    "                )\n",
    "                .sort(\"importance\", descending=True)\n",
    "                .head(20)\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Top XGBoost features:\\n{feature_importance.to_dicts()}\")\n",
    "            self.mlflow_manager.log_params(\n",
    "                {\n",
    "                    f\"xgb_top_feature_{idx}\": f\"{row[0]} ({row[1]:.4f})\"\n",
    "                    for idx, row in enumerate(feature_importance.iter_rows(), start=1)\n",
    "                }\n",
    "            )\n",
    "\n",
    "            results[\"xgboost\"] = {\n",
    "                \"model\": xgb_model,\n",
    "                \"metrics\": xgb_metrics,\n",
    "                \"predictions\": xgb_pred,\n",
    "            }\n",
    "\n",
    "            # ================================\n",
    "            # ======= LightGBM Training ======\n",
    "            # ================================\n",
    "            try:\n",
    "                lgb_model = self.train_lightgbm(X_train, y_train, X_val, y_val)\n",
    "                lgb_pred = lgb_model.predict(X_test)\n",
    "                lgb_metrics = self.calculate_metrics(y_test, lgb_pred)\n",
    "\n",
    "                self.mlflow_manager.log_metrics(\n",
    "                    {f\"lightgbm_{k}\": v for k, v in lgb_metrics.items()}\n",
    "                )\n",
    "                self.mlflow_manager.log_model(\n",
    "                    lgb_model, \"lightgbm\", input_example=X_train_df.head()\n",
    "                )\n",
    "\n",
    "                # Log feature importance for LightGBM\n",
    "                lgb_importance: pl.DataFrame = (\n",
    "                    pl.DataFrame(\n",
    "                        {\n",
    "                            \"feature\": self.feature_cols,\n",
    "                            \"importance\": lgb_model.feature_importances_,\n",
    "                        }\n",
    "                    )\n",
    "                    .sort(\"importance\", descending=True)\n",
    "                    .head(20)\n",
    "                )\n",
    "                logger.info(f\"Top LightGBM features:\\n{lgb_importance.to_dicts()}\")\n",
    "                self.mlflow_manager.log_params(\n",
    "                    {\n",
    "                        f\"lgb_top_feature_{idx}\": f\"{row[0]} ({row[1]:.4f})\"\n",
    "                        for idx, row in enumerate(lgb_importance.iter_rows(), start=1)\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                results[\"lightgbm\"] = {\n",
    "                    \"model\": lgb_model,\n",
    "                    \"metrics\": lgb_metrics,\n",
    "                    \"predictions\": lgb_pred,\n",
    "                }\n",
    "            except Exception as lgb_err:\n",
    "                logger.exception(f\"âŒ Skipping LightGBM due to error: {lgb_err}\")\n",
    "\n",
    "            # ================================\n",
    "            # ====== Ensemble Training =======\n",
    "            # ================================\n",
    "            # Weighted ensemble based on individual model performance (using validation R2)\n",
    "            # Ensemble: if LightGBM is present, use weighted; otherwise fall back to XGBoost only\n",
    "            xgb_val_pred = xgb_model.predict(X_val)\n",
    "            xgb_val_r2 = r2_score(y_val, xgb_val_pred)\n",
    "\n",
    "            if \"lightgbm\" in results:\n",
    "                lgb_val_pred = results[\"lightgbm\"][\"model\"].predict(X_val)\n",
    "                lgb_val_r2 = r2_score(y_val, lgb_val_pred)\n",
    "\n",
    "                # Calculate weights with a minimum weight constraint\n",
    "                min_weight = 0.2\n",
    "                xgb_weight: float = max(\n",
    "                    min_weight, xgb_val_r2 / (xgb_val_r2 + lgb_val_r2)\n",
    "                )\n",
    "                lgb_weight: float = max(\n",
    "                    min_weight, lgb_val_r2 / (xgb_val_r2 + lgb_val_r2)\n",
    "                )\n",
    "                total_weight = xgb_weight + lgb_weight\n",
    "                xgb_weight /= total_weight\n",
    "                lgb_weight /= total_weight\n",
    "                logger.info(\n",
    "                    f\"â­ Ensemble weights - XGBoost: {xgb_weight:.3f}, LightGBM: {lgb_weight:.3f}\"\n",
    "                )\n",
    "\n",
    "                ensemble_weights: dict[str, float] = {\n",
    "                    \"xgboost\": xgb_weight,\n",
    "                    \"lightgbm\": lgb_weight,\n",
    "                }\n",
    "                ensemble_pred = (\n",
    "                    xgb_weight * xgb_pred\n",
    "                    + lgb_weight * results[\"lightgbm\"][\"predictions\"]\n",
    "                )\n",
    "                ensemble_models = {\n",
    "                    \"xgboost\": xgb_model,\n",
    "                    \"lightgbm\": results[\"lightgbm\"][\"model\"],\n",
    "                }\n",
    "\n",
    "            else:\n",
    "                logger.info(\"LightGBM not available; using XGBoost-only ensemble\")\n",
    "                ensemble_weights = {\"xgboost\": 1.0}\n",
    "                ensemble_pred = xgb_pred\n",
    "                ensemble_models = {\"xgboost\": xgb_model}\n",
    "\n",
    "            if \"prophet\" in results:\n",
    "                ensemble_models[\"prophet\"] = results[\"prophet\"][\"model\"]\n",
    "                ensemble_weights = {\n",
    "                    \"xgboost\": 1 / 3,\n",
    "                    \"lightgbm\": 1 / 3,\n",
    "                    \"prophet\": 1 / 3,\n",
    "                }\n",
    "\n",
    "            ensemble_model = EnsembleModel(ensemble_models, ensemble_weights)\n",
    "\n",
    "            # Save ensemble model\n",
    "            self.models[\"ensemble\"] = ensemble_model\n",
    "\n",
    "            ensemble_metrics: dict[str, float] = self.calculate_metrics(\n",
    "                y_test, ensemble_pred\n",
    "            )\n",
    "\n",
    "            self.mlflow_manager.log_metrics(\n",
    "                {f\"ensemble_{k}\": v for k, v in ensemble_metrics.items()}\n",
    "            )\n",
    "            self.mlflow_manager.log_model(\n",
    "                ensemble_model, \"ensemble\", input_example=None\n",
    "            )\n",
    "\n",
    "            results[\"ensemble\"] = {\n",
    "                \"model\": ensemble_model,\n",
    "                \"metrics\": ensemble_metrics,\n",
    "                \"predictions\": ensemble_pred,\n",
    "            }\n",
    "\n",
    "            # Run diagnostics\n",
    "            logger.info(\"Running model diagnostics...\")\n",
    "            test_predictions: dict[str, np.ndarray | None] = {\n",
    "                \"xgboost\": xgb_pred if \"xgboost\" in results else None,\n",
    "                \"lightgbm\": lgb_pred if \"lightgbm\" in results else None,\n",
    "                \"ensemble\": ensemble_pred,\n",
    "            }\n",
    "\n",
    "            diagnosis: dict[str, Any] = diagnose_model_performance(\n",
    "                train_df, val_df, test_df, test_predictions, target_col\n",
    "            )\n",
    "\n",
    "            logger.info(\"Diagnostic recommendations:\")\n",
    "            for rec in diagnosis[\"recommendations\"]:\n",
    "                logger.warning(f\"- {rec}\")\n",
    "\n",
    "            # Generate visualizations\n",
    "            logger.info(\"ðŸš¨ Generating model comparison visualizations...\")\n",
    "            try:\n",
    "                self._generate_and_log_visualizations(results, test_df)\n",
    "            except Exception as viz_error:\n",
    "                logger.error(\n",
    "                    f\"Visualization generation failed: {viz_error}\", exc_info=True\n",
    "                )\n",
    "\n",
    "            # Save artifacts\n",
    "            self.save_artifacts()\n",
    "\n",
    "            # Get current run ID for verification\n",
    "            current_run_id = mlflow.active_run().info.run_id  # type: ignore\n",
    "\n",
    "            # End MLflow run\n",
    "            self.mlflow_manager.end_run()\n",
    "\n",
    "            logger.info(\"Syncing artifacts to S3...\")\n",
    "            try:\n",
    "                s3_manager = MLflowS3Manager()\n",
    "                s3_manager.sync_mlflow_artifacts_to_s3(current_run_id)\n",
    "                logger.info(\"âœ… Successfully synced artifacts to S3\")\n",
    "\n",
    "                # Verify S3 artifacts after sync\n",
    "                logger.info(\"Verifying S3 artifact storage...\")\n",
    "                verification_results = verify_s3_artifacts(\n",
    "                    run_id=current_run_id,\n",
    "                    expected_artifacts=[\n",
    "                        \"models/\",\n",
    "                        \"scalers.pkl\",\n",
    "                        \"encoders.pkl\",\n",
    "                        \"feature_cols.pkl\",\n",
    "                        \"visualizations/\",\n",
    "                        \"reports/\",\n",
    "                    ],\n",
    "                )\n",
    "                log_s3_verification_results(verification_results)\n",
    "\n",
    "                if not verification_results[\"success\"]:\n",
    "                    logger.warning(\"S3 artifact verification failed after sync\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"âŒ Failed to sync artifacts to S3: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.mlflow_manager.end_run(status=\"FAILED\")\n",
    "            raise e\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _generate_and_log_visualizations(\n",
    "        self,\n",
    "        results: dict[str, Any],\n",
    "        test_df: pl.DataFrame,\n",
    "        viz_backend: Literal[\"matplotlib\", \"plotly\"] = \"matplotlib\",\n",
    "    ) -> None:\n",
    "        \"\"\"Generate and log model comparison visualizations to MLflow\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Starting visualization generation...\")\n",
    "            if viz_backend == \"plotly\":\n",
    "                visualizer = ModelVisualizerPlotly()\n",
    "            else:\n",
    "                visualizer = ModelVisualizerMatMatplotlib()\n",
    "\n",
    "            # Extract metrics\n",
    "            metrics_dict: dict[str, Any] = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if \"metrics\" in model_results:\n",
    "                    metrics_dict[model_name] = model_results[\"metrics\"]\n",
    "\n",
    "            # Prepare predictions data\n",
    "            predictions_dict: dict[str, Any] = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if (\n",
    "                    \"predictions\" in model_results\n",
    "                    and model_results[\"predictions\"] is not None\n",
    "                ):\n",
    "                    pred_df: pl.DataFrame = test_df.select([\"date\"]).clone()\n",
    "                    # Visualizer expects a column named 'prediction' (singular)\n",
    "                    pred_df = pred_df.with_columns(\n",
    "                        pl.Series(\"prediction\", values=model_results[\"predictions\"])\n",
    "                    )\n",
    "                    predictions_dict[model_name] = pred_df\n",
    "\n",
    "            # Extract feature importance if available\n",
    "            feature_importance_dict = {}\n",
    "            for model_name, model_results in results.items():\n",
    "                if model_name in [\"xgboost\", \"lightgbm\"] and \"model\" in model_results:\n",
    "                    model: Any = model_results[\"model\"]\n",
    "                    if hasattr(model, \"feature_importances_\"):\n",
    "                        importance_df = pl.DataFrame(\n",
    "                            {\n",
    "                                \"feature\": self.feature_cols,\n",
    "                                \"importance\": model.feature_importances_,\n",
    "                            }\n",
    "                        ).sort(\"importance\", descending=True)\n",
    "                        feature_importance_dict[model_name] = importance_df\n",
    "\n",
    "            # Create temporary directory for visualizations\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                logger.info(\n",
    "                    f\"ðŸš¨ Creating visualizations in temporary directory: {temp_dir}\"\n",
    "                )\n",
    "\n",
    "                # Generate all visualizations\n",
    "                saved_files = visualizer.create_comprehensive_report(\n",
    "                    metrics_dict=metrics_dict,\n",
    "                    predictions_dict=predictions_dict,\n",
    "                    actual_data=test_df,\n",
    "                    feature_importance_dict=feature_importance_dict\n",
    "                    if feature_importance_dict\n",
    "                    else None,\n",
    "                    save_dir=temp_dir,\n",
    "                )\n",
    "\n",
    "                logger.info(\n",
    "                    f\"âœ… Generated {len(saved_files)} visualization files: {list(saved_files.keys())}\"\n",
    "                )\n",
    "\n",
    "                # Log each visualization to MLflow\n",
    "                for viz_name, file_path in saved_files.items():\n",
    "                    if os.path.exists(file_path):\n",
    "                        mlflow.log_artifact(file_path, \"visualizations\")  # type: ignore\n",
    "                        logger.info(\n",
    "                            f\"Logged visualization: {viz_name} from {file_path}\"\n",
    "                        )\n",
    "                    else:\n",
    "                        logger.warning(f\"Visualization file not found: {file_path}\")\n",
    "\n",
    "                # Also create a combined HTML report\n",
    "                self._create_combined_html_report(saved_files, temp_dir)\n",
    "\n",
    "                # Log the combined report\n",
    "                combined_report = os.path.join(temp_dir, \"model_comparison_report.html\")\n",
    "                if os.path.exists(combined_report):\n",
    "                    mlflow.log_artifact(combined_report, \"reports\")  # type: ignore\n",
    "                    logger.info(\"âœ… Logged combined HTML report\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Don't fail the entire run\n",
    "            logger.error(f\"âŒ Failed to generate visualizations: {e}\")\n",
    "\n",
    "    def _create_combined_html_report(\n",
    "        self, saved_files: dict[str, str], save_dir: str\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create a combined HTML report with all visualizations.\n",
    "\n",
    "        The HTML report includes all visualizations in a single page for easy comparison.\n",
    "        \"\"\"\n",
    "\n",
    "        html_content: str = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html>\n",
    "        <head>\n",
    "            <title>Model Comparison Report</title>\n",
    "            <style>\n",
    "                body {{\n",
    "                    font-family: Arial, sans-serif;\n",
    "                    margin: 20px;\n",
    "                    background-color: #f5f5f5;\n",
    "                }}\n",
    "                h1, h2 {{\n",
    "                    color: #333;\n",
    "                }}\n",
    "                .section {{\n",
    "                    background-color: white;\n",
    "                    padding: 20px;\n",
    "                    margin-bottom: 20px;\n",
    "                    border-radius: 8px;\n",
    "                    box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "                }}\n",
    "                .timestamp {{\n",
    "                    color: #666;\n",
    "                    font-size: 14px;\n",
    "                }}\n",
    "                iframe {{\n",
    "                    width: 100%;\n",
    "                    height: 800px;\n",
    "                    border: 1px solid #ddd;\n",
    "                    border-radius: 4px;\n",
    "                    margin-top: 10px;\n",
    "                }}\n",
    "                img {{\n",
    "                    max-width: 100%;\n",
    "                    height: auto;\n",
    "                    border-radius: 4px;\n",
    "                    margin-top: 10px;\n",
    "                }}\n",
    "            </style>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>Sales Forecast Model Comparison Report</h1>\n",
    "            <p class=\"timestamp\">Generated on: {timestamp}</p>\n",
    "        \"\"\"\n",
    "\n",
    "        html_content: str = html_content.format(\n",
    "            timestamp=datetime.now().isoformat(timespec=\"seconds\")\n",
    "        )\n",
    "\n",
    "        # Add each visualization section\n",
    "        sections: list[tuple[str, str]] = [\n",
    "            (\"metrics_comparison\", \"Model Performance Metrics\"),\n",
    "            (\"predictions_comparison\", \"Predictions Comparison\"),\n",
    "            (\"residuals_analysis\", \"Residuals Analysis\"),\n",
    "            (\"error_distribution\", \"Error Distribution\"),\n",
    "            (\"feature_importance\", \"Feature Importance\"),\n",
    "            (\"summary\", \"Summary Statistics\"),\n",
    "        ]\n",
    "\n",
    "        for key, title in sections:\n",
    "            if key in saved_files:\n",
    "                html_content += f'<div class=\"section\"><h2>{title}</h2>'\n",
    "\n",
    "                # All files are now PNG - base64 encode them\n",
    "                with open(saved_files[key], \"rb\") as f:\n",
    "                    img_data = base64.b64encode(f.read()).decode()\n",
    "                html_content += (\n",
    "                    f'<img src=\"data:image/png;base64,{img_data}\" alt=\"{title}\">'\n",
    "                )\n",
    "\n",
    "                html_content += \"</div>\"\n",
    "\n",
    "        html_content += \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        # Save the combined report\n",
    "        with open(os.path.join(save_dir, \"model_comparison_report.html\"), \"w\") as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "    def save_artifacts(self) -> None:\n",
    "        \"\"\"\n",
    "        Saves artifacts to disk in the expected format for MLflow.\n",
    "\n",
    "        Saves the following artifacts:\n",
    "        - scalers.pkl: Joblib dump of the scalers used for feature scaling\n",
    "        - encoders.pkl: Joblib dump of the encoders used for categorical encoding\n",
    "        - feature_cols.pkl: Joblib dump of the feature column names\n",
    "        - models/xgboost/xgboost_model.pkl: Joblib dump of the XGBoost model\n",
    "        - models/lightgbm/lightgbm_model.pkl: Joblib dump of the LightGBM model\n",
    "        - models/ensemble/ensemble_model.pkl: Joblib dump of the ensemble model\n",
    "\n",
    "        Also logs the artifacts to MLflow.\n",
    "        \"\"\"\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts\", exist_ok=True)\n",
    "\n",
    "        joblib.dump(self.scalers, f\"{PACKAGE_PATH}/artifacts/scalers.pkl\")\n",
    "        joblib.dump(self.label_encoders, f\"{PACKAGE_PATH}/artifacts/encoders.pkl\")\n",
    "        joblib.dump(self.feature_cols, f\"{PACKAGE_PATH}/artifacts/feature_cols.pkl\")\n",
    "\n",
    "        # Save individual models in the expected format\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/xgboost\", exist_ok=True)\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/lightgbm\", exist_ok=True)\n",
    "        os.makedirs(f\"{PACKAGE_PATH}/artifacts/models/ensemble\", exist_ok=True)\n",
    "\n",
    "        if \"xgboost\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"xgboost\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/xgboost/xgboost_model.pkl\",\n",
    "            )\n",
    "\n",
    "        if \"lightgbm\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"lightgbm\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/lightgbm/lightgbm_model.pkl\",\n",
    "            )\n",
    "\n",
    "        if \"ensemble\" in self.models:\n",
    "            joblib.dump(\n",
    "                self.models[\"ensemble\"],\n",
    "                f\"{PACKAGE_PATH}/artifacts/models/ensemble/ensemble_model.pkl\",\n",
    "            )\n",
    "\n",
    "        self.mlflow_manager.log_artifacts(f\"{PACKAGE_PATH}/artifacts\")\n",
    "\n",
    "        logger.info(\"âœ… Artifacts saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38954065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23621787",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70fe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp: str = \"../../../../Documents/data_dump/bike_data/database.parquet\"\n",
    "data: pl.DataFrame = pl.read_parquet(fp)\n",
    "console.print(f\"Shape: {data.shape}\", style=\"info\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab353a",
   "metadata": {},
   "source": [
    "### Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7513bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ml.feature_engineering import (\n",
    "    FeatureConfig,\n",
    "    FeatureEngineer,\n",
    "    InteractionFeats,\n",
    "    Lags,\n",
    "    Windows,\n",
    "    create_lag_features,\n",
    ")\n",
    "\n",
    "# train_data, test_data = split_temporal_data(data, test_size=0.2)\n",
    "# train_data.shape, test_data.shape\n",
    "\n",
    "create_lag_features(\n",
    "    nw.from_native(data.to_pandas()), target_col=\"cnt\", lags=[1, 2, 3]\n",
    ").head()  # .to_native()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {},
   "outputs": [],
   "source": [
    "config: FeatureConfig = FeatureConfig(\n",
    "    lags=[Lags(feature=\"cnt\", lags=[1, 2, 3]), Lags(feature=\"temp\", lags=[1, 2, 3])],\n",
    "    diffs=[Lags(feature=\"cnt\", lags=[1]), Lags(feature=\"temp\", lags=[1])],\n",
    "    interactions=[\n",
    "        InteractionFeats(feature_1=\"cnt\", feature_2=\"temp\", operation=\"add\"),\n",
    "        InteractionFeats(feature_1=\"cnt\", feature_2=\"temp\", operation=\"multiply\"),\n",
    "    ],\n",
    "    rolling_windows=[\n",
    "        Windows(feature=\"cnt\", windows=[3, 7]),\n",
    "        Windows(feature=\"temp\", windows=[3, 7]),\n",
    "    ],\n",
    "    drop_feats=[\"atemp\", \"windspeed\", \"cnt\"],\n",
    "    target_col=\"cnt\",\n",
    ")\n",
    "\n",
    "# # Lags\n",
    "# for lag in config.lags:\n",
    "#     df = create_lag_features(\n",
    "#         nw.from_native(data.to_pandas()), target_col=lag.feature, lags=lag.lags\n",
    "#     )\n",
    "# # Diffs\n",
    "# for diff in config.diffs:\n",
    "#     df = create_difference_features(\n",
    "#         nw.from_native(df.to_pandas()), target_col=diff.feature, lags=diff.lags\n",
    "#     )\n",
    "# # Interactions\n",
    "# for interaction in config.interactions:\n",
    "#     df = create_interaction_features(\n",
    "#         nw.from_native(df.to_pandas()),\n",
    "#         feature_1=interaction.feature_1,\n",
    "#         feature_2=interaction.feature_2,\n",
    "#         operation=interaction.operation,\n",
    "#     )\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea4dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_eng = FeatureEngineer(data, config)\n",
    "\n",
    "feat_eng.create_all_features().null_count().sum_horizontal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame({\"age\": [25, 30, 35], \"salary\": [50000, 60000, 70000]})\n",
    "\n",
    "df = df.with_columns(pl.col(\"age\").shift(0).alias(\"age_shift_0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcb2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config: FeatureConfig = FeatureConfig(\n",
    "    lags=[\n",
    "        Lags(feature=\"cnt\", lags=[0, 1, 24]),\n",
    "        Lags(feature=\"hr\", lags=[1, 24]),\n",
    "        Lags(feature=\"temp\", lags=[1, 3]),\n",
    "        Lags(feature=\"hum\", lags=[1, 3]),\n",
    "    ],\n",
    "    diffs=[\n",
    "        Lags(feature=\"cnt\", lags=[1, 2]),\n",
    "        Lags(feature=\"hr\", lags=[1, 24]),\n",
    "        Lags(feature=\"temp\", lags=[1, 2, 24]),\n",
    "        Lags(feature=\"hum\", lags=[1, 2]),\n",
    "    ],\n",
    "    interactions=[\n",
    "        InteractionFeats(feature_1=\"temp\", feature_2=\"hum\", operation=\"add\"),\n",
    "        InteractionFeats(feature_1=\"hum\", feature_2=\"hr\", operation=\"add\"),\n",
    "    ],\n",
    "    rolling_windows=[\n",
    "        Windows(feature=\"temp\", windows=[3, 6]),\n",
    "        Windows(feature=\"hum\", windows=[3, 6]),\n",
    "    ],\n",
    "    drop_feats=[\"yr\", \"atemp\", \"casual\", \"registered\", \"datetime\", \"cnt\"],\n",
    "    target_col=\"cnt\",\n",
    ")\n",
    "\n",
    "feat_eng = FeatureEngineer(data, config)\n",
    "\n",
    "prepr_data: pl.DataFrame = feat_eng.create_all_features()\n",
    "prepr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e57e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb97f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from src.ml.utils import compute_metrics, split_temporal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17c2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = split_temporal_data(prepr_data)\n",
    "x_train = train_df.drop(\"target\").to_numpy()\n",
    "y_train = train_df[\"target\"].to_numpy()\n",
    "\n",
    "x_test = test_df.drop(\"target\").to_numpy()\n",
    "y_test = test_df[\"target\"].to_numpy()\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24727bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits: int = 5\n",
    "test_size: int = 168  # 1 week of hourly data\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits, test_size=test_size, gap=0)\n",
    "rf_reg = RandomForestRegressor(random_state=123)\n",
    "all_rmse: list[float] = []\n",
    "all_mae: list[float] = []\n",
    "all_mape: list[float] = []\n",
    "print(tscv)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(tscv.split(x_train), start=1):\n",
    "    print(f\"Fold {i}:\")\n",
    "    x_tr, x_val = x_train[train_index], x_train[test_index]\n",
    "    y_tr, y_val = y_train[train_index], y_train[test_index]\n",
    "    # Train the model\n",
    "    rf_reg.fit(x_tr, y_tr)\n",
    "    # Evaluate the model\n",
    "    y_pred = rf_reg.predict(x_val)\n",
    "    metrics = compute_metrics(y_val, y_pred)\n",
    "    print(f\"Validation Metrics: {metrics}\")\n",
    "    all_rmse.append(metrics.get(\"RMSE\"))\n",
    "    all_mae.append(metrics.get(\"MAE\"))\n",
    "    all_mape.append(metrics.get(\"MAPE\"))\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average MAE over {n_splits} folds: {np.mean(all_mae).round(2)}\")\n",
    "print(f\"Average RMSE over {n_splits} folds: {np.mean(all_rmse).round(2)}\")\n",
    "print(f\"Average MAPE over {n_splits} folds: {np.mean(all_mape).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dde1952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "y_test_pred = rf_reg.predict(x_test)\n",
    "metrics_test = compute_metrics(y_test, y_test_pred)\n",
    "print(f\"\\nTest Set Metrics: {metrics_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89a8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe7caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e152c6c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061c811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428fb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bike-Rental-Prediction (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
